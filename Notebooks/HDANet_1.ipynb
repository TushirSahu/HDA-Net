{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2EE9qdg8tz3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a2EE9qdg8tz3",
    "outputId": "580997d9-fb2d-4445-854c-10be10384d4e"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "CV1mdn_axJ7D",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CV1mdn_axJ7D",
    "outputId": "aff1f178-075d-4441-da63-0c916eeb4a85"
   },
   "outputs": [],
   "source": [
    "# !unzip '/content/drive/MyDrive/ddr/ddr.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1650c40",
   "metadata": {
    "id": "e1650c40"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-17 18:40:27.262101: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from keras import layers\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.layers import MaxPool2D,GlobalAveragePooling2D,Conv2D,Average,Reshape,Concatenate,Multiply,LayerNormalization,AveragePooling2D,GlobalMaxPool2D,Conv1D,BatchNormalization\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.applications.inception_v3 import InceptionV3 \n",
    "# from keras.applications.inception_v2 import InceptionV2 \n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications import ResNet50\n",
    "from keras.layers.core import Lambda\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.layers import Dense,Reshape,Activation,Permute,Dot,Dropout,ReLU,Add\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import *\n",
    "# from keras.utils import multi_gpu_model\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import load_model\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a96c3ec",
   "metadata": {
    "id": "3a96c3ec"
   },
   "outputs": [],
   "source": [
    "def Global_Attention_Block(inputs):\n",
    "        shape=K.int_shape(inputs)\n",
    "#         avg_pool=GlobalAveragePooling2D()(inputs)\n",
    "        avg_pool=AveragePooling2D(pool_size=(shape[1],shape[2])) (inputs)\n",
    "        avg_pool=Conv2D(shape[3],1,padding='same')(avg_pool)\n",
    "        avg_pool=Activation('sigmoid')(avg_pool)\n",
    "        avg_pool=Conv2D(shape[3],1,padding='same')(avg_pool)\n",
    "        avg_pool=Activation('sigmoid')(avg_pool)\n",
    "        \n",
    "        C_A= Multiply()([inputs,avg_pool])\n",
    "        avg_pool=Lambda(lambda x: K.mean(x,axis=-1,keepdims=True))(C_A)\n",
    "        avg_pool=Activation('sigmoid')(avg_pool)\n",
    "        S_A= Multiply()([avg_pool,C_A])\n",
    "        return S_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "xPR8YkbsPej4",
   "metadata": {
    "id": "xPR8YkbsPej4"
   },
   "outputs": [],
   "source": [
    "def ChannelAttention(inputs,ratio):\n",
    "    channels = inputs.shape[-1]\n",
    "    l1=Dense(channels//ratio,activation='relu',use_bias=False)\n",
    "    l2=Dense(channels,use_bias=False)\n",
    "\n",
    "\n",
    "    avg_pool = GlobalAveragePooling2D()(inputs)\n",
    "    avg_pool=l1(avg_pool)\n",
    "    avg_pool=l2(avg_pool)\n",
    "\n",
    "    max_pool=GlobalMaxPool2D()(inputs)\n",
    "    max_pool=l1(max_pool)\n",
    "    max_pool=l2(max_pool)\n",
    "\n",
    "    fc2 =max_pool+avg_pool\n",
    "    fc2 = Activation('sigmoid')(fc2)\n",
    "    attention = Multiply()([inputs, fc2])\n",
    "    return attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "483d7b99",
   "metadata": {
    "id": "483d7b99"
   },
   "outputs": [],
   "source": [
    "def Category_Attention_Block(inputs,classes,k):\n",
    "    shape=K.int_shape(inputs)\n",
    "    F_1=Conv2D(k*classes,1,padding='same')(inputs)\n",
    "    F_1=BatchNormalization()(F_1)\n",
    "    F1=Activation('sigmoid')(F_1)\n",
    "    \n",
    "    F_2=F1\n",
    "    x=GlobalMaxPool2D()(F_2)\n",
    "    x=Reshape((classes,k)) (x)\n",
    "    S=Lambda(lambda x: K.mean(x,axis=-1,keepdims=False))(x)\n",
    "    \n",
    "    x=Reshape((shape[1],shape[2],classes,k)) (F1)\n",
    "    x=Lambda(lambda x: K.mean(x,axis=-1,keepdims=False))(x)\n",
    "    x=Multiply()([S,x])\n",
    "    M=Lambda(lambda x: K.mean(x,axis=-1,keepdims=True))(x)\n",
    "    \n",
    "    semantic=Multiply()([inputs,M])\n",
    "    return semantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67f1f2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(inputs):\n",
    "    shape=K.int_shape(inputs)\n",
    "    x=AveragePooling2D(pool_size=(shape[1],shape[2])) (inputs)\n",
    "    x=Conv2D(shape[3]//2,(1,1),padding='same') (x)\n",
    "    x=Activation('relu') (x)\n",
    "    x=Conv2D(shape[3],(1,1), padding='same') (x)\n",
    "    x=Activation('sigmoid') (x)\n",
    "    C_A=Multiply()([x,inputs])\n",
    "    \n",
    "    return C_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03f54055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_attention(inputs):\n",
    "    shape=K.int_shape(inputs)\n",
    "    x1=Lambda(lambda x: K.mean(x,axis=-1,keepdims=True))(inputs)\n",
    "    \n",
    "    x1=Conv2D(shape[3],(1,1),padding='same')(x1)\n",
    "    \n",
    "    x1=Activation('sigmoid')(x1)\n",
    "    \n",
    "    x=Multiply()([x1,inputs])\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "jvlEmK4Rbey1",
   "metadata": {
    "id": "jvlEmK4Rbey1"
   },
   "outputs": [],
   "source": [
    "def globalchannelattention(inputs):\n",
    "    shape=K.int_shape(inputs)\n",
    "    num_filters=shape[-1]\n",
    "  \n",
    "    initial=GlobalAveragePooling2D()(inputs)\n",
    "    initial=Reshape((1,num_filters))(initial)\n",
    "\n",
    "    a=Conv1D(num_filters,1,padding='same')(initial)\n",
    "    a=Activation('sigmoid')(a)\n",
    "\n",
    "    b=Conv1D(num_filters,1,padding='same')(initial)\n",
    "    b=Activation('sigmoid')(b)\n",
    "\n",
    "    b=K.permute_dimensions(b,(0,2,1))\n",
    "\n",
    "    out=K.batch_dot(b,a,axes=(2,1))\n",
    "    out=Activation('softmax')(out)\n",
    "\n",
    "    c=Reshape((shape[1]*shape[2],num_filters))(inputs)\n",
    "\n",
    "    final=K.batch_dot(c,out,axes=(2,1))\n",
    "\n",
    "    final=Reshape((shape[1],shape[2],shape[3]))(final)\n",
    "\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "Jys1-J7N5kme",
   "metadata": {
    "id": "Jys1-J7N5kme"
   },
   "outputs": [],
   "source": [
    "def SelfAttention(inputs,ratio):\n",
    "   shape=K.int_shape(inputs)\n",
    "   num_filters=shape[-1]\n",
    "  #query\n",
    "   x_q=Conv2D(shape[-1]//ratio,(3,3),padding='same')(inputs)\n",
    "   x_q=Activation('sigmoid')(x_q)\n",
    "   x_qnew=Reshape((shape[1]*shape[2],shape[3]//ratio))(x_q)\n",
    "\n",
    "  #key\n",
    "   x_k=Conv2D(shape[-1]//ratio,(1,1),padding='same')(inputs)\n",
    "   x_k=Activation('sigmoid')(x_k)\n",
    "   x_knew=Reshape((shape[1]*shape[2],shape[3]//ratio))(x_k)\n",
    "  \n",
    "   x_knew=K.permute_dimensions(x_knew,(0,2,1))\n",
    "  #value\n",
    "   x_v=Conv2D(shape[-1]//ratio,(1,1),padding='same')(inputs)\n",
    "   x_v=Activation('softmax')(x_v)\n",
    "   x_vnew=Reshape((shape[1]*shape[2],shape[3]//ratio))(x_v)\n",
    "\n",
    "\n",
    "   x=K.batch_dot(x_qnew, x_knew,axes=(2,1))\n",
    "   x1=Activation('softmax')(x)\n",
    "    \n",
    "   x2=K.batch_dot(x1, x_vnew,axes=(2,1))\n",
    "\n",
    "   x_final=Reshape((shape[1],shape[2],shape[3]//ratio))(x2)\n",
    "\n",
    "   x_final=Conv2D(shape[-1],(1,1),padding='same')(x_final)\n",
    "\n",
    "   x_final=Activation('softmax')(x_final)\n",
    "\n",
    "   x_final=Add()([x_final,inputs])\n",
    "\n",
    "   return x_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8131d33",
   "metadata": {
    "id": "c8131d33"
   },
   "outputs": [],
   "source": [
    "def smooth_curve(points, factor=0.9):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4475ceba",
   "metadata": {
    "id": "4475ceba"
   },
   "outputs": [],
   "source": [
    "   \n",
    "def plotmodel(history,name):\n",
    "    \n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1) \n",
    "    \n",
    "    plt.figure(1)                  \n",
    "    plt.plot(epochs,smooth_curve(acc))\n",
    "    plt.plot(epochs,smooth_curve(val_acc))\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train_acc', 'val_accuracy'], loc='upper left')\n",
    "    plt.title(name)\n",
    "    plt.savefig('acc_'+name+'.png')\n",
    "    \n",
    "    plt.figure(2)\n",
    "    plt.plot(epochs,smooth_curve(loss))\n",
    "    plt.plot(epochs,smooth_curve(val_loss))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train_loss', 'val_loss'], loc='upper right')\n",
    "    plt.title(name)\n",
    "    plt.savefig('loss_'+name+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89d1e574",
   "metadata": {
    "id": "89d1e574"
   },
   "outputs": [],
   "source": [
    "def get_base_model(model_name,img_size):\n",
    "    if(model_name=='vgg19'):\n",
    "        base_model=VGG19(include_top=False,weights='imagenet',input_shape=(img_size,img_size,3))\n",
    "    if model_name =='densenet121':\n",
    "        base_model=DenseNet121(include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "    if(model_name=='inceptionv3'):\n",
    "        base_model=InceptionV3(include_top=False,weights='imagenet',input_shape=(img_size,img_size,3))\n",
    "    if(model_name=='resnet50'):\n",
    "        base_model=ResNet50(include_top=False,weights='imagenet',input_shape=(img_size,img_size,3))\n",
    "    if(model_name=='mobilenet'):\n",
    "        base_model=MobileNet(include_top=False,weights='imagenet',input_shape=(img_size,img_size,3))\n",
    "    if(model_name=='mobilenet1.0'):\n",
    "        base_model=MobileNet(include_top=False,weights='imagenet',alpha=1.0,input_shape=(img_size,img_size,3))\n",
    "    if(model_name=='xception'):\n",
    "        base_model=Xception(include_top=False,weights='imagenet',input_shape=(img_size,img_size,3))\n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "AtTqXNdGDIeJ",
   "metadata": {
    "id": "AtTqXNdGDIeJ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "import tensorflow as tf\n",
    "\n",
    "def weighted_cross_entropy(alpha=0.62,beta=0.68):\n",
    "    def loss_function(y_true, y_pred):\n",
    "            \n",
    "        weight = tf.where(tf.math.equal(y_true,1),alpha,1.0 - alpha)\n",
    "        weight=tf.where(tf.math.equal(y_true,3),beta,weight)\n",
    "#          weight = tf.where(tf.math.logical_or(tf.math.equal(y_true,3),tf.math.equal(y_true,1)),alpha,1.0 - alpha)\n",
    "#         weight=tf.where(y_true==1,alpha,1.0-alpha)\n",
    "        loss = CategoricalCrossentropy()(y_true, y_pred)\n",
    "        weighted_loss = loss * weight\n",
    "        return weighted_loss\n",
    "\n",
    "    return loss_function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee25f2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_hierarchical(last3,last2,last1,ratio):\n",
    "    height3,width3,_ = last3.shape[1],last3.shape[2],last3.shape[3]\n",
    "    \n",
    "    height2,width2,_ = last2.shape[1],last2.shape[2],last2.shape[3]\n",
    "    height1,width1,_ = last1.shape[1],last1.shape[2],last1.shape[3]\n",
    "\n",
    "    num_filters=last3.shape[-1]//2\n",
    "\n",
    "    input1=Conv2D(num_filters,(1,1),padding='same')(last3)  #h1xw1xc\n",
    "    input2=Conv2D(num_filters,(1,1),padding='same')(last2)  #h2xw2xc\n",
    "    input3=Conv2D(num_filters,(1,1),padding='same')(last1)  #h3xw3xc\n",
    "\n",
    "    inp1=Reshape((height3*width3,num_filters))(input1) #h1w1xc\n",
    "\n",
    "    inp2=Reshape((height2*width2,num_filters))(input2) #h2w2xc\n",
    "\n",
    "    inp3=Reshape((height1*width1,num_filters))(input3) #h3w3xc\n",
    "    \n",
    "\n",
    "    k2=K.permute_dimensions(inp2,(0,2,1))  #cxh2w2\n",
    "\n",
    "    x=K.batch_dot(inp1,k2,axes=(2,1)) #h1w1xh2w2\n",
    "\n",
    "    x=Activation('softmax')(x)\n",
    "\n",
    "    x1=K.batch_dot(x,inp1,axes=(2,1)) #h1w1xc\n",
    "\n",
    "    k3=K.permute_dimensions(inp3,(0,2,1)) #cxh3w3\n",
    "\n",
    "    x2=K.batch_dot(inp1,k3,axes=(2,1)) #h1w1xh3w3\n",
    "    x2=Activation('softmax')(x2)\n",
    "    \n",
    "    x2=K.batch_dot(x2,inp1,axes=(2,1)) #h1w1xc\n",
    "\n",
    "    \n",
    "    x_final=Concatenate()([x1,x2,inp1])\n",
    "    x_final=Reshape((height3,width3,x_final.shape[-1]))(x_final)\n",
    "    x_final=Conv2D(last3.shape[-1],(1,1),padding='same')(x_final)\n",
    "    x_final=Activation('softmax')(x_final)\n",
    "    \n",
    "   \n",
    "    x_final=Add()([x_final,last3])\n",
    "    \n",
    "\n",
    "    return x_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8feddef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_att(inputs):\n",
    "    shape=K.int_shape(inputs)\n",
    "    \n",
    "    x=Conv2D(shape[-1],(1,1),padding='same')(inputs)\n",
    "    x=Activation('sigmoid')(x)\n",
    "    \n",
    "    x=Multiply()([x,inputs])\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88f5990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_model(last3,last2,last1):\n",
    "#     shape = last3\n",
    "    height,width,channels = last3.shape[1],last3.shape[2],last3.shape[3]\n",
    "    input1=Reshape((height*width,last3.shape[-1]))(last3) #h1w1xc1\n",
    "\n",
    "    input2=Reshape((height*width,last2.shape[-1]))(last2) #h1w1xc2\n",
    "\n",
    "    input3=Reshape((height*width,last1.shape[-1]))(last1) #h1w1xc3\n",
    "\n",
    "    k2=K.permute_dimensions(input2,(0,2,1)) # c2xh1w1\n",
    "\n",
    "    x=K.batch_dot(k2,input1,axes=(2,1))  #c2xc1\n",
    "    x=Activation('softmax')(x)\n",
    "\n",
    "    x1=K.batch_dot(input1, x,axes=(2,1)) #h1w1xc1\n",
    "\n",
    "    x1=Reshape((height,width,x1.shape[-1]))(x1) #h1xw1xc1\n",
    "\n",
    "    k3=K.permute_dimensions(input3,(0,2,1)) # c3xh1w1\n",
    "    \n",
    "    x2=K.batch_dot(k3,input1,axes=(2,1)) #c3xc1\n",
    "    x2=Activation('softmax')(x2)\n",
    "\n",
    "    x2=K.batch_dot(input1,x2,axes=(2,1)) #h1w1xc1\n",
    "\n",
    "    x2=Reshape((height,width,x2.shape[-1]))(x2) #h1xw1xc1\n",
    "    \n",
    "    x_final=Concatenate()([x1,x2,last3])\n",
    "   \n",
    "    x_final=Conv2D(channels,(1,1),padding='same')(x_final)\n",
    "    x_final=Activation('softmax')(x_final)\n",
    "  \n",
    "\n",
    "    return x_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcc2807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GSAM(inputs,channel_inp):\n",
    "    shape=K.int_shape(inputs)\n",
    "    x1=AveragePooling2D(pool_size=(shape[1],shape[2]))(inputs)\n",
    "    x2=MaxPool2D(pool_size=(shape[1],shape[2]))(inputs)\n",
    "    \n",
    "    x3=AveragePooling2D(pool_size=(shape[1],shape[2]))(channel_inp)\n",
    "    x4=MaxPool2D(pool_size=(shape[1],shape[2]))(channel_inp)\n",
    "    \n",
    "    x1=Add()([x1,x3])\n",
    "    x1=Activation('sigmoid')(x1)\n",
    "    \n",
    "    x2=Add()([x2,x4])\n",
    "    x2=Activation('sigmoid')(x2)\n",
    "    \n",
    "    x_final=Concatenate()([x2,x1])\n",
    "    \n",
    "    x_final=Conv2D(shape[-1],(1,1),padding='same')(x_final)\n",
    "    x_final=Activation('sigmoid')(x_final)\n",
    "    \n",
    "    x_final=Multiply()([x_final,channel_inp])\n",
    "    \n",
    "    return x_final\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "540ba35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint=tf.keras.constraints.min_max_norm(max_value=1,min_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "392d8f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedSum(layers.Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(WeightedSum, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape=1):\n",
    "        self.a = self.add_weight( name='alpha',shape=( 1, 1, 1),initializer='random_normal',dtype='float32',trainable=True,\n",
    "            constraint = constraint,)\n",
    "        self.b = self.add_weight(name='beta',shape=( 1, 1, 1),initializer='random_normal',dtype='float32',trainable=True,constraint = constraint,)\n",
    "        \n",
    "#         self.c = self.add_weight(name='gamma',shape=( 1, 1, 1),initializer='random_normal',dtype='float32',trainable=True,constraint = constraint,)\n",
    "        super(WeightedSum, self).build(input_shape)\n",
    "\n",
    "    def call(self, model_outputs):\n",
    "#         return tf.multiply(model_outputs[0],self.a) + tf.multiply(model_outputs[1], self.b) + tf.multiply(model_outputs[2], self.c)\n",
    "        return tf.multiply(model_outputs[0],self.a) + tf.multiply(model_outputs[1], self.b) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "LXy-hSA6BjnY",
   "metadata": {
    "id": "LXy-hSA6BjnY"
   },
   "outputs": [],
   "source": [
    "def rotateToAttend(input_feature):\n",
    "  shape = K.int_shape(input_feature)\n",
    "  # HxwxC\n",
    "  permute_1 =tf.keras.layers.Permute((3,2,1),input_shape=(shape[1],shape[2],shape[3]))(input_feature) \n",
    "  #  cxwxh\n",
    "  x1 = Lambda(lambda x: K.mean(x,axis=-1,keepdims=True))(permute_1)\n",
    "  x2 = Lambda(lambda x: K.max(x,axis=-1,keepdims=True))(permute_1)\n",
    "  x3 = tf.keras.layers.Concatenate(axis=-1)([x1, x2])\n",
    "  x = Conv2D(1,1, padding='same', dilation_rate=(1, 1)) (x1)\n",
    "  x = tf.keras.layers.BatchNormalization(epsilon=1e-5, momentum=0.01)(x)\n",
    "  x = tf.keras.activations.sigmoid(x)  \n",
    "  x = tf.keras.layers.Multiply()([x,permute_1])\n",
    "  F1 = tf.keras.layers.Permute((3,2,1),input_shape=(shape[1],shape[2],shape[3]))(x)\n",
    "\n",
    "  permute_2 = tf.keras.layers.Permute((1,3,2),input_shape=(shape[1],shape[2],shape[3]))(input_feature)\n",
    "  x1 = Lambda(lambda x: K.mean(x,axis=-1,keepdims=True))(permute_2)\n",
    "  x2 = Lambda(lambda x: K.max(x,axis=-1,keepdims=True))(permute_2)\n",
    "  x3 = tf.keras.layers.Concatenate(axis=-1)([x1, x2])\n",
    "  x = Conv2D(1,1, padding='same', dilation_rate=(1, 1)) (x1)\n",
    "  x = tf.keras.layers.BatchNormalization(epsilon=1e-5, momentum=0.01)(x)\n",
    "  x = tf.keras.activations.sigmoid(x)  \n",
    "  x = tf.keras.layers.Multiply()([x,permute_2])\n",
    "  F2 = tf.keras.layers.Permute((1,3,2),input_shape=(shape[1],shape[2],shape[3]))(x)\n",
    "\n",
    "\n",
    "  permute_3 = input_feature\n",
    "  x1 = Lambda(lambda x: K.mean(x,axis=-1,keepdims=True))(permute_3)\n",
    "  x2 = Lambda(lambda x: K.max(x,axis=-1,keepdims=True))(permute_3)\n",
    "  x3 = tf.keras.layers.Concatenate(axis=-1)([x1, x2])\n",
    "  x = Conv2D(1,1, padding='same', dilation_rate=(1, 1)) (x1)\n",
    "  x = tf.keras.layers.BatchNormalization(epsilon=1e-5, momentum=0.01)(x)\n",
    "  x = tf.keras.activations.sigmoid(x)  \n",
    "  F3 = tf.keras.layers.Multiply()([x,permute_3])\n",
    "\n",
    "  attend_feature = tf.keras.layers.Average()([F1, F2, F3])\n",
    "  return attend_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7edc9257",
   "metadata": {
    "id": "7edc9257"
   },
   "outputs": [],
   "source": [
    "def train_model(model,image_size,batch_size,save_name,lr1,lr2,Epochs1,Epochs2):\n",
    "\n",
    "    train_dir_fold='/home/dipankar/dipankar/tushir/ddr/train'\n",
    "    val_dir_fold='/home/dipankar/dipankar/tushir/ddr/validation'\n",
    "\n",
    "    train_num,valid_num=6260,2503 \n",
    "\n",
    "    train=ImageDataGenerator(rescale=1./255,horizontal_flip=True,vertical_flip=True,rotation_range=90)     \n",
    "\n",
    "    valid = ImageDataGenerator(rescale=1./255)\n",
    "      \n",
    "    train_data = train.flow_from_directory(train_dir_fold, target_size=(image_size, image_size),shuffle=True,\n",
    "                                                  batch_size=batch_size)\n",
    "    val_data = valid.flow_from_directory(val_dir_fold, target_size=(image_size, image_size),shuffle=False,\n",
    "                                                 batch_size=batch_size)\n",
    "                                                  \n",
    "      \n",
    "    \n",
    "    \n",
    "    \n",
    "    lr_decay=ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=3, verbose=1)\n",
    "    save_model=ModelCheckpoint('new/'+save_name+'{epoch:02d}.h5', monitor='val_loss',save_best_only=True,mode='min')\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "         layer.trainable=False\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=lr1,decay=0.00001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    model.fit(train_data,steps_per_epoch=train_num/batch_size,validation_data=val_data,validation_steps=valid_num/batch_size,\n",
    "              epochs=Epochs1,workers=2,callbacks=[lr_decay,save_model])\n",
    "     \n",
    "    for layer in base_model.layers:\n",
    "         layer.trainable = True\n",
    "        \n",
    "    model.compile(optimizer=Adam(learning_rate=lr2,decay=0.00001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    history=model.fit(train_data,steps_per_epoch=train_num/batch_size,validation_data=val_data,\n",
    "                      validation_steps=valid_num/batch_size,epochs=Epochs2,workers=2,\n",
    "                       callbacks=[lr_decay,save_model])\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50a26fb8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "50a26fb8",
    "outputId": "665a44d8-bfa7-44e2-a8c1-9190784f1f9d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-17 18:40:29.878996: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-06-17 18:40:29.880447: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-06-17 18:40:29.992946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:18:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2023-06-17 18:40:29.993788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:3b:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2023-06-17 18:40:29.993820: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-06-17 18:40:29.996851: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-06-17 18:40:29.996951: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-06-17 18:40:29.999598: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-06-17 18:40:30.000038: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-06-17 18:40:30.003300: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-06-17 18:40:30.005279: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-06-17 18:40:30.012185: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-06-17 18:40:30.015604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2023-06-17 18:40:30.016187: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-17 18:40:30.019222: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-06-17 18:40:30.334999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:18:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2023-06-17 18:40:30.335842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:3b:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2023-06-17 18:40:30.335886: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-06-17 18:40:30.335939: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-06-17 18:40:30.335957: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-06-17 18:40:30.335974: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-06-17 18:40:30.335991: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-06-17 18:40:30.336008: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-06-17 18:40:30.336024: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-06-17 18:40:30.336044: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-06-17 18:40:30.338970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2023-06-17 18:40:30.339029: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-06-17 18:40:31.619984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-06-17 18:40:31.620027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 \n",
      "2023-06-17 18:40:31.620035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N N \n",
      "2023-06-17 18:40:31.620040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   N N \n",
      "2023-06-17 18:40:31.622561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10070 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:18:00.0, compute capability: 7.5)\n",
      "2023-06-17 18:40:31.624184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10070 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:3b:00.0, compute capability: 7.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 518, 518, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 256, 256, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 256, 256, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 256, 256, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 258, 258, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 128, 128, 64) 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 128, 128, 64) 4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 128, 128, 64) 0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 128, 128, 64) 36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 128, 128, 64) 0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 128, 128, 256 16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 128, 128, 256 16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 128, 128, 256 1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 128, 128, 256 1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 128, 128, 256 0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 128, 128, 256 0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 128, 128, 64) 16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 128, 128, 64) 0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 128, 128, 64) 36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 128, 128, 64) 0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 128, 128, 256 16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 128, 128, 256 1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 128, 128, 256 0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 128, 128, 256 0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 128, 128, 64) 16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 128, 128, 64) 0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 128, 128, 64) 36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 128, 128, 64) 0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 128, 128, 256 16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 128, 128, 256 1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 128, 128, 256 0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 128, 128, 256 0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 64, 64, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 64, 64, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 64, 64, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 64, 64, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 64, 64, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 64, 64, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 64, 64, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 64, 64, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 64, 64, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 64, 64, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 64, 64, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 64, 64, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 64, 64, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 64, 64, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 64, 64, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 64, 64, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 64, 64, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 64, 64, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 64, 64, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 64, 64, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 64, 64, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 64, 64, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 64, 64, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 64, 64, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 64, 64, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 64, 64, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 64, 64, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 64, 64, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 64, 64, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 64, 64, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 32, 32, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 32, 32, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 32, 32, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 32, 32, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 32, 32, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 32, 32, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 32, 32, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 32, 32, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 32, 32, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 32, 32, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 32, 32, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 32, 32, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 32, 32, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 32, 32, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 32, 32, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 32, 32, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 32, 32, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 32, 32, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 32, 32, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 32, 32, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 32, 32, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 32, 32, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 32, 32, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 32, 32, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 32, 32, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 32, 32, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 32, 32, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 32, 32, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 32, 32, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 32, 32, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 32, 32, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 32, 32, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 32, 32, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 32, 32, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 32, 32, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 32, 32, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 32, 32, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 32, 32, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 32, 32, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 32, 32, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 32, 32, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 32, 32, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 32, 32, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 32, 32, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 16, 16, 512)  524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 16, 16, 512)  2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 16, 16, 512)  0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 16, 16, 512)  2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 16, 16, 512)  2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 16, 16, 512)  0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 16, 16, 2048) 2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 16, 16, 2048) 1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 16, 16, 2048) 8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 16, 16, 2048) 8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 16, 16, 2048) 0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 16, 16, 2048) 0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 16, 16, 512)  1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 16, 16, 512)  2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 16, 16, 512)  0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 16, 16, 512)  2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 16, 16, 512)  2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 16, 16, 512)  0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 16, 16, 2048) 1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 16, 16, 2048) 8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 16, 16, 2048) 0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 16, 16, 2048) 0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 16, 16, 512)  1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 16, 16, 512)  2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 16, 16, 512)  0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 16, 16, 512)  2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 16, 16, 512)  2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 16, 16, 512)  0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 16, 16, 2048) 1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 16, 16, 2048) 8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 16, 16, 2048) 0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 16, 16, 2048) 0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 16, 16, 1024) 2098176     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 16, 16, 1024) 2098176     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 16, 16, 1024) 2098176     conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 256, 1024)    0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 256, 1024)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 256, 1024)    0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose (TFOpLam (None, 1024, 256)    0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose_1 (TFOpL (None, 1024, 256)    0           reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 256, 2048)    0           conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 256, 2048)    0           conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.linalg.matmul (TFOpLambda)   (None, 256, 256)     0           reshape[0][0]                    \n",
      "                                                                 tf.compat.v1.transpose[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.linalg.matmul_2 (TFOpLambda) (None, 256, 256)     0           reshape[0][0]                    \n",
      "                                                                 tf.compat.v1.transpose_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 256, 2048)    0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose_2 (TFOpL (None, 2048, 256)    0           reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose_3 (TFOpL (None, 2048, 256)    0           reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 256, 256)     0           tf.linalg.matmul[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 256, 256)     0           tf.linalg.matmul_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.linalg.matmul_4 (TFOpLambda) (None, 2048, 2048)   0           tf.compat.v1.transpose_2[0][0]   \n",
      "                                                                 reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.linalg.matmul_6 (TFOpLambda) (None, 2048, 2048)   0           tf.compat.v1.transpose_3[0][0]   \n",
      "                                                                 reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.linalg.matmul_1 (TFOpLambda) (None, 256, 1024)    0           activation[0][0]                 \n",
      "                                                                 reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.linalg.matmul_3 (TFOpLambda) (None, 256, 1024)    0           activation_1[0][0]               \n",
      "                                                                 reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 2048, 2048)   0           tf.linalg.matmul_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 2048, 2048)   0           tf.linalg.matmul_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 256, 3072)    0           tf.linalg.matmul_1[0][0]         \n",
      "                                                                 tf.linalg.matmul_3[0][0]         \n",
      "                                                                 reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.linalg.matmul_5 (TFOpLambda) (None, 256, 2048)    0           reshape_4[0][0]                  \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.linalg.matmul_7 (TFOpLambda) (None, 256, 2048)    0           reshape_4[0][0]                  \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 16, 16, 3072) 0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 16, 16, 2048) 0           tf.linalg.matmul_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 16, 16, 2048) 0           tf.linalg.matmul_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 16, 16, 2048) 6293504     reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 16, 16, 6144) 0           reshape_7[0][0]                  \n",
      "                                                                 reshape_8[0][0]                  \n",
      "                                                                 conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 16, 16, 2048) 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 2048) 12584960    concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 16, 16, 2048) 0           activation_2[0][0]               \n",
      "                                                                 conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 2048) 0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 16, 16, 4096) 0           add[0][0]                        \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 4096)         0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 5)            20485       global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 48,781,189\n",
      "Trainable params: 48,728,069\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D, Dropout, Dense\n",
    "\n",
    "k = 5\n",
    "lr1 = 0.005\n",
    "lr2 = 0.0001\n",
    "batch_size = 12\n",
    "image_size = 512\n",
    "classes = 5\n",
    "\n",
    "\n",
    "base_model=ResNet50(include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\n",
    "base_in = base_model.input\n",
    "base_out=base_model.output\n",
    "\n",
    "\n",
    "last3 = base_model.get_layer('conv5_block3_out').output\n",
    "last2 = base_model.get_layer('conv5_block2_out').output\n",
    "last1 = base_model.get_layer('conv5_block1_out').output\n",
    "\n",
    "\n",
    "# last3=Conv2D(base_out.shape[-1],(1,1),padding='same')(last3)\n",
    "# last2=Conv2D(base_out.shape[-1]//2,(1,1),padding='same')(last2)\n",
    "# last1=Conv2D(base_out.shape[-1]//2,(1,1),padding='same')(last1)\n",
    "\n",
    "# x=Concatenate()([last3,last2,last1])\n",
    "\n",
    "\n",
    "# x1 = globalchannelattention(base_out)\n",
    "x1 = spatial_hierarchical(last3,last2,last1,2)\n",
    "x2 = new_model(last3,last2,last1)\n",
    "# x = globalchannelattention(compress)\n",
    "# x2 = SelfAttention(compress, 2)\n",
    "\n",
    "# x2=spatial_attention(base_out)\n",
    "\n",
    "\n",
    "# x1=rotateToAttend(base_out)\n",
    "# x2=point_att(base_out)\n",
    "# x3=attention(base_out)\n",
    "\n",
    "# x=Add()([x1,x2,x3])\n",
    "# x=WeightedSum()([x1,x2,x3])\n",
    "\n",
    "x=Concatenate()([x1,x2])\n",
    "\n",
    "# x=Add()([last3,x1])\n",
    "\n",
    "# x=Multiply()([x1,last3])\n",
    "# x=WeightedSum()([last3,x])\n",
    "\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "out = Dense(classes, activation='softmax')(x)\n",
    "\n",
    "parallel_model = Model(base_in, out)\n",
    "parallel_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075496dd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "075496dd",
    "outputId": "b085b717-c3d4-4469-a0cb-47b20750a624"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6260 images belonging to 5 classes.\n",
      "Found 2503 images belonging to 5 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-17 18:40:41.505078: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2023-06-17 18:40:41.526515: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz\n",
      "2023-06-17 18:40:44.766304: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-06-17 18:40:45.778549: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-06-17 18:40:47.096658: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256\n",
      "2023-06-17 18:40:47.217383: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/521 [=====>........................] - ETA: 2:58 - loss: 1.7553 - accuracy: 0.4454"
     ]
    }
   ],
   "source": [
    "history=train_model(parallel_model,image_size,batch_size,'resnet_global_channel',lr1,lr2,1,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smyEy7KklWjd",
   "metadata": {
    "id": "smyEy7KklWjd"
   },
   "outputs": [],
   "source": [
    "plotmodel(history,'resnet_global_channel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "j8G2Jd4GdB0h",
   "metadata": {
    "id": "j8G2Jd4GdB0h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3759 images belonging to 5 classes.\n",
      "314/314 [==============================] - 88s 277ms/step - loss: 0.6347 - accuracy: 0.7829\n",
      "Test Loss: 0.6346911787986755, Test Accuracy: 0.7829210162162781\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix,f1_score,roc_auc_score\n",
    "\n",
    "loss_function=weighted_cross_entropy()\n",
    "# keras.utils.register_keras_serializable('loss_function')(loss_function)\n",
    "\n",
    "with keras.utils.custom_object_scope({'loss_function':loss_function}):\n",
    "         model_name='/home/dipankar/dipankar/tushir/new/resnet_global_channel10_(78.29).h5'\n",
    "         model = load_model(model_name)\n",
    "\n",
    "test_dir = '/home/dipankar/dipankar/tushir/ddr/test/' \n",
    "batch_size = 12\n",
    "image_size=512\n",
    "test_data = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(image_size, image_size),\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "loss, accuracy = model.evaluate(test_data)\n",
    "\n",
    "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a2a19b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1802    9   68    0    1]\n",
      " [  73   17   99    0    0]\n",
      " [ 320   50  962    5    7]\n",
      " [   1    0   44   22    4]\n",
      " [  18    1  107    9  140]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "y_true = test_data.classes\n",
    "y_pred = model.predict(test_data)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "confusion_mtx = confusion_matrix(y_true, y_pred_classes)\n",
    "print(confusion_mtx)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(confusion_mtx,annot=True,fmt='d',cmap='Blues')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14628f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76460048600986\n",
      "0.8800220651711166\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,f1_score,roc_auc_score\n",
    "\n",
    "f=f1_score(y_true,y_pred_classes,average='weighted')\n",
    "roc=roc_auc_score(y_true,y_pred,average='weighted',multi_class='ovo')\n",
    "print(f)\n",
    "print(roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76c0ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_kappa(result,test_num):\n",
    "    weight=np.zeros((5,5),dtype='float')\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            weight[i,j]=(i-j)*(i-j)/16\n",
    "    fenzi=0\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            fenzi=fenzi+result[i,j]*weight[i,j]\n",
    "    fenmu=0\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            fenmu=fenmu+weight[i,j]*result[:,j].sum()*result[i,:].sum()\n",
    "\n",
    "    weght_kappa=1-(fenzi/(fenmu/test_num))\n",
    "    return  weght_kappa\n",
    "\n",
    "\n",
    "test_num=0\n",
    "result=np.zeros((5,5),dtype=int)\n",
    "recall=np.zeros((1,5),dtype=float)\n",
    "for i in range(5):\n",
    "        datadirs=test_dir+str(i)+'/'\n",
    "        filenames=os.listdir(datadirs)\n",
    "        num=len(filenames)\n",
    "        test_num=test_num+num\n",
    "        valid = ImageDataGenerator(rescale=1./255)\n",
    "        valid_data=valid.flow_from_directory(directory=test_dir,target_size=(image_size,image_size),\n",
    "                                             batch_size=batch_size,class_mode=None,classes=str(i))\n",
    "        predict=model.predict_generator(valid_data,steps=num/batch_size,verbose=1,workers=1)\n",
    "        predict=np.argmax(predict,axis=-1)\n",
    "        for j in range(5):\n",
    "            result[i,j]=np.sum(predict==j)\n",
    "\n",
    "# right=result[0,0]+result[1,1]+result[2,2]+result[3,3]+result[4,4]\n",
    "# print('Acc:',right/test_num)\n",
    "\n",
    "w_kappa=weight_kappa(result,test_num)\n",
    "print('w_kappa:',w_kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RD11r5fCGlZf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "id": "RD11r5fCGlZf",
    "outputId": "1d446e7d-4981-47b2-954c-efc4de3fc528"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def grad_cam(model, image_path, layer_name, class_index, image_size):\n",
    "    img = image.load_img(image_path, target_size=(image_size, image_size))\n",
    "    img_orig = img.copy()\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "\n",
    "    grad_model = Model(inputs=model.input, outputs=(model.get_layer(layer_name).output, model.output))\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img)\n",
    "        loss = predictions[:, class_index]\n",
    "\n",
    "    output = conv_outputs[0]\n",
    "    grads = tape.gradient(loss, conv_outputs)[0]\n",
    "\n",
    "    weights = tf.reduce_mean(grads, axis=(0, 1))\n",
    "    cam = np.dot(output, weights)\n",
    "\n",
    "    cam = cv2.resize(cam, (image_size, image_size))\n",
    "    cam = np.maximum(cam, 0)\n",
    "    cam = cam / np.max(cam)\n",
    "\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
    "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    img_orig = np.array(img_orig) \n",
    "    overlaid_img = cv2.addWeighted(img_orig, 0.7, heatmap, 0.3, 0)\n",
    "\n",
    "    return overlaid_img\n",
    "\n",
    "\n",
    "image_path = '/home/dipankar/dipankar/tushir/ddr/train/3/007-2766-100.jpg'  \n",
    "layer_name = 'reshape_2'  \n",
    "class_index =4\n",
    "\n",
    "image_size = 512 \n",
    "\n",
    "overlaid_img  = grad_cam(parallel_model, image_path, layer_name, class_index, image_size)\n",
    "original_img = image.load_img(image_path, target_size=(image_size, image_size))\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].imshow(original_img)\n",
    "axs[0].axis('off')\n",
    "axs[0].set_title('Original Image')\n",
    "axs[1].imshow(overlaid_img)\n",
    "axs[1].axis('off')\n",
    "axs[1].set_title('Overlaid Image with Heatmap')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "c268c1f4b20d46e39df77955af542fe69fc17facdbea48218bd0d6964daf30ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
