{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"c268c1f4b20d46e39df77955af542fe69fc17facdbea48218bd0d6964daf30ad"}}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install gdown","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a2EE9qdg8tz3","outputId":"580997d9-fb2d-4445-854c-10be10384d4e","execution":{"iopub.status.busy":"2023-06-17T19:27:42.561414Z","iopub.execute_input":"2023-06-17T19:27:42.561849Z","iopub.status.idle":"2023-06-17T19:27:54.994340Z","shell.execute_reply.started":"2023-06-17T19:27:42.561813Z","shell.execute_reply":"2023-06-17T19:27:54.993248Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting gdown\n  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.12.0)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.28.2)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from gdown) (1.16.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.64.1)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2023.5.7)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nInstalling collected packages: gdown\nSuccessfully installed gdown-4.7.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# https://drive.google.com/file/d/1oYmjfv8JCVq__gSUGXuXH-uXFs1WmiOz/view?usp=sharing\n!gdown --id 1oYmjfv8JCVq__gSUGXuXH-uXFs1WmiOz","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CV1mdn_axJ7D","outputId":"aff1f178-075d-4441-da63-0c916eeb4a85","execution":{"iopub.status.busy":"2023-06-17T19:27:54.997786Z","iopub.execute_input":"2023-06-17T19:27:54.998643Z","iopub.status.idle":"2023-06-17T19:28:16.032047Z","shell.execute_reply.started":"2023-06-17T19:27:54.998603Z","shell.execute_reply":"2023-06-17T19:28:16.030922Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/gdown/cli.py:126: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom (uriginal): https://drive.google.com/uc?id=1oYmjfv8JCVq__gSUGXuXH-uXFs1WmiOz\nFrom (redirected): https://drive.google.com/uc?id=1oYmjfv8JCVq__gSUGXuXH-uXFs1WmiOz&confirm=t&uuid=1a601756-53b8-4489-a4fc-83e089797f31\nTo: /kaggle/working/ddr.zip\n100%|███████████████████████████████████████| 3.20G/3.20G [00:18<00:00, 172MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"import zipfile\n\nz= zipfile.ZipFile('/kaggle/working/ddr.zip')\nz.extractall()","metadata":{"execution":{"iopub.status.busy":"2023-06-17T19:28:16.033748Z","iopub.execute_input":"2023-06-17T19:28:16.034447Z","iopub.status.idle":"2023-06-17T19:28:39.964550Z","shell.execute_reply.started":"2023-06-17T19:28:16.034408Z","shell.execute_reply":"2023-06-17T19:28:39.963629Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import keras\nfrom keras import backend as K\nimport numpy as np\nimport glob\nimport tensorflow as tf\nimport shutil\nfrom tensorflow.keras import regularizers\n\nfrom keras import layers\nfrom sklearn.model_selection import StratifiedKFold\nfrom keras.layers import MaxPool2D,GlobalAveragePooling2D,Conv2D,Average,Reshape,Concatenate,Multiply,LayerNormalization,AveragePooling2D,GlobalMaxPool2D,Conv1D,BatchNormalization\nfrom keras.applications.mobilenet_v2 import MobileNetV2\nfrom keras.applications.densenet import DenseNet121\nfrom keras.applications.inception_v3 import InceptionV3 \n# from keras.applications.inception_v2 import InceptionV2 \nfrom keras.applications.densenet import DenseNet121\nfrom keras.applications.vgg19 import VGG19\nfrom keras.applications import ResNet50\nfrom keras.layers.core import Lambda\nfrom sklearn.metrics import roc_auc_score\nfrom keras.applications.xception import Xception\nfrom keras.applications.mobilenet import MobileNet\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom keras.layers import Dense,Reshape,Activation,Permute,Dot,Dropout,ReLU,Add\nfrom keras.models import Model\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import *\n# from keras.utils import multi_gpu_model\nfrom matplotlib import pyplot as plt\nfrom keras.models import load_model\nimport os","metadata":{"id":"e1650c40","execution":{"iopub.status.busy":"2023-06-17T19:28:39.967486Z","iopub.execute_input":"2023-06-17T19:28:39.967860Z","iopub.status.idle":"2023-06-17T19:28:49.239552Z","shell.execute_reply.started":"2023-06-17T19:28:39.967827Z","shell.execute_reply":"2023-06-17T19:28:49.238440Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"def Global_Attention_Block(inputs):\n        shape=K.int_shape(inputs)\n#         avg_pool=GlobalAveragePooling2D()(inputs)\n        avg_pool=AveragePooling2D(pool_size=(shape[1],shape[2])) (inputs)\n        avg_pool=Conv2D(shape[3],1,padding='same')(avg_pool)\n        avg_pool=Activation('sigmoid')(avg_pool)\n        avg_pool=Conv2D(shape[3],1,padding='same')(avg_pool)\n        avg_pool=Activation('sigmoid')(avg_pool)\n        \n        C_A= Multiply()([inputs,avg_pool])\n        avg_pool=Lambda(lambda x: K.mean(x,axis=-1,keepdims=True))(C_A)\n        avg_pool=Activation('sigmoid')(avg_pool)\n        S_A= Multiply()([avg_pool,C_A])\n        return S_A","metadata":{"id":"3a96c3ec","execution":{"iopub.status.busy":"2023-06-17T19:28:49.240861Z","iopub.execute_input":"2023-06-17T19:28:49.241667Z","iopub.status.idle":"2023-06-17T19:28:49.249317Z","shell.execute_reply.started":"2023-06-17T19:28:49.241635Z","shell.execute_reply":"2023-06-17T19:28:49.248339Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def ChannelAttention(inputs,ratio):\n    channels = inputs.shape[-1]\n    l1=Dense(channels//ratio,activation='relu',use_bias=False)\n    l2=Dense(channels,use_bias=False)\n\n\n    avg_pool = GlobalAveragePooling2D()(inputs)\n    avg_pool=l1(avg_pool)\n    avg_pool=l2(avg_pool)\n\n    max_pool=GlobalMaxPool2D()(inputs)\n    max_pool=l1(max_pool)\n    max_pool=l2(max_pool)\n\n    fc2 =max_pool+avg_pool\n    fc2 = Activation('sigmoid')(fc2)\n    attention = Multiply()([inputs, fc2])\n    return attention","metadata":{"id":"xPR8YkbsPej4","execution":{"iopub.status.busy":"2023-06-17T19:28:49.250626Z","iopub.execute_input":"2023-06-17T19:28:49.251170Z","iopub.status.idle":"2023-06-17T19:28:49.262584Z","shell.execute_reply.started":"2023-06-17T19:28:49.251136Z","shell.execute_reply":"2023-06-17T19:28:49.261736Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def Category_Attention_Block(inputs,classes,k):\n    shape=K.int_shape(inputs)\n    F_1=Conv2D(k*classes,1,padding='same')(inputs)\n    F_1=BatchNormalization()(F_1)\n    F1=Activation('sigmoid')(F_1)\n    \n    F_2=F1\n    x=GlobalMaxPool2D()(F_2)\n    x=Reshape((classes,k)) (x)\n    S=Lambda(lambda x: K.mean(x,axis=-1,keepdims=False))(x)\n    \n    x=Reshape((shape[1],shape[2],classes,k)) (F1)\n    x=Lambda(lambda x: K.mean(x,axis=-1,keepdims=False))(x)\n    x=Multiply()([S,x])\n    M=Lambda(lambda x: K.mean(x,axis=-1,keepdims=True))(x)\n    \n    semantic=Multiply()([inputs,M])\n    return semantic","metadata":{"id":"483d7b99","execution":{"iopub.status.busy":"2023-06-17T19:28:49.264425Z","iopub.execute_input":"2023-06-17T19:28:49.265096Z","iopub.status.idle":"2023-06-17T19:28:49.274249Z","shell.execute_reply.started":"2023-06-17T19:28:49.265064Z","shell.execute_reply":"2023-06-17T19:28:49.273328Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def attention(inputs):\n    shape=K.int_shape(inputs)\n    x=AveragePooling2D(pool_size=(shape[1],shape[2])) (inputs)\n    x=Conv2D(shape[3]//2,(1,1),padding='same') (x)\n    x=Activation('relu') (x)\n    x=Conv2D(shape[3],(1,1), padding='same') (x)\n    x=Activation('sigmoid') (x)\n    C_A=Multiply()([x,inputs])\n    \n    return C_A","metadata":{"execution":{"iopub.status.busy":"2023-06-17T19:28:49.275838Z","iopub.execute_input":"2023-06-17T19:28:49.276240Z","iopub.status.idle":"2023-06-17T19:28:49.285650Z","shell.execute_reply.started":"2023-06-17T19:28:49.276207Z","shell.execute_reply":"2023-06-17T19:28:49.284571Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def spatial_attention(inputs):\n    shape=K.int_shape(inputs)\n    x1=Lambda(lambda x: K.mean(x,axis=-1,keepdims=True))(inputs)\n    \n    x1=Conv2D(shape[3],(1,1),padding='same')(x1)\n    \n    x1=Activation('sigmoid')(x1)\n    \n    x=Multiply()([x1,inputs])\n    \n    return x","metadata":{"execution":{"iopub.status.busy":"2023-06-17T19:28:49.289775Z","iopub.execute_input":"2023-06-17T19:28:49.290035Z","iopub.status.idle":"2023-06-17T19:28:49.299732Z","shell.execute_reply.started":"2023-06-17T19:28:49.290012Z","shell.execute_reply":"2023-06-17T19:28:49.298862Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def globalchannelattention(inputs):\n    shape=K.int_shape(inputs)\n    num_filters=shape[-1]\n  \n    initial=GlobalAveragePooling2D()(inputs)\n    initial=Reshape((1,num_filters))(initial)\n\n    a=Conv1D(num_filters,1,padding='same')(initial)\n    a=Activation('sigmoid')(a)\n\n    b=Conv1D(num_filters,1,padding='same')(initial)\n    b=Activation('sigmoid')(b)\n\n    b=K.permute_dimensions(b,(0,2,1))\n\n    out=K.batch_dot(b,a,axes=(2,1))\n    out=Activation('softmax')(out)\n\n    c=Reshape((shape[1]*shape[2],num_filters))(inputs)\n\n    final=K.batch_dot(c,out,axes=(2,1))\n\n    final=Reshape((shape[1],shape[2],shape[3]))(final)\n\n    return final","metadata":{"id":"jvlEmK4Rbey1","execution":{"iopub.status.busy":"2023-06-17T19:28:49.301106Z","iopub.execute_input":"2023-06-17T19:28:49.301574Z","iopub.status.idle":"2023-06-17T19:28:49.310892Z","shell.execute_reply.started":"2023-06-17T19:28:49.301539Z","shell.execute_reply":"2023-06-17T19:28:49.310054Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def SelfAttention(inputs,ratio):\n   shape=K.int_shape(inputs)\n   num_filters=shape[-1]\n  #query\n   x_q=Conv2D(shape[-1]//ratio,(3,3),padding='same')(inputs)\n   x_q=Activation('sigmoid')(x_q)\n   x_qnew=Reshape((shape[1]*shape[2],shape[3]//ratio))(x_q)\n\n  #key\n   x_k=Conv2D(shape[-1]//ratio,(1,1),padding='same')(inputs)\n   x_k=Activation('sigmoid')(x_k)\n   x_knew=Reshape((shape[1]*shape[2],shape[3]//ratio))(x_k)\n  \n   x_knew=K.permute_dimensions(x_knew,(0,2,1))\n  #value\n   x_v=Conv2D(shape[-1]//ratio,(1,1),padding='same')(inputs)\n   x_v=Activation('softmax')(x_v)\n   x_vnew=Reshape((shape[1]*shape[2],shape[3]//ratio))(x_v)\n\n\n   x=K.batch_dot(x_qnew, x_knew,axes=(2,1))\n   x1=Activation('softmax')(x)\n    \n   x2=K.batch_dot(x1, x_vnew,axes=(2,1))\n\n   x_final=Reshape((shape[1],shape[2],shape[3]//ratio))(x2)\n\n   x_final=Conv2D(shape[-1],(1,1),padding='same')(x_final)\n\n   x_final=Activation('softmax')(x_final)\n\n   x_final=Add()([x_final,inputs])\n\n   return x_final","metadata":{"id":"Jys1-J7N5kme","execution":{"iopub.status.busy":"2023-06-17T19:28:49.313707Z","iopub.execute_input":"2023-06-17T19:28:49.314404Z","iopub.status.idle":"2023-06-17T19:28:49.325735Z","shell.execute_reply.started":"2023-06-17T19:28:49.314358Z","shell.execute_reply":"2023-06-17T19:28:49.324919Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def smooth_curve(points, factor=0.9):\n    smoothed_points = []\n    for point in points:\n        if smoothed_points:\n            previous = smoothed_points[-1]\n            smoothed_points.append(previous * factor + point * (1 - factor))\n        else:\n            smoothed_points.append(point)\n    return smoothed_points    ","metadata":{"id":"c8131d33","execution":{"iopub.status.busy":"2023-06-17T19:28:49.327134Z","iopub.execute_input":"2023-06-17T19:28:49.327779Z","iopub.status.idle":"2023-06-17T19:28:49.339478Z","shell.execute_reply.started":"2023-06-17T19:28:49.327749Z","shell.execute_reply":"2023-06-17T19:28:49.338649Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"   \ndef plotmodel(history,name):\n    \n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    epochs = range(1, len(acc) + 1) \n    \n    plt.figure(1)                  \n    plt.plot(epochs,smooth_curve(acc))\n    plt.plot(epochs,smooth_curve(val_acc))\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train_acc', 'val_accuracy'], loc='upper left')\n    plt.title(name)\n    plt.savefig('acc_'+name+'.png')\n    \n    plt.figure(2)\n    plt.plot(epochs,smooth_curve(loss))\n    plt.plot(epochs,smooth_curve(val_loss))\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train_loss', 'val_loss'], loc='upper right')\n    plt.title(name)\n    plt.savefig('loss_'+name+'.png')","metadata":{"id":"4475ceba","execution":{"iopub.status.busy":"2023-06-17T19:28:49.340890Z","iopub.execute_input":"2023-06-17T19:28:49.341535Z","iopub.status.idle":"2023-06-17T19:28:49.350354Z","shell.execute_reply.started":"2023-06-17T19:28:49.341504Z","shell.execute_reply":"2023-06-17T19:28:49.349493Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def get_base_model(model_name,img_size):\n    if(model_name=='vgg19'):\n        base_model=VGG19(include_top=False,weights='imagenet',input_shape=(img_size,img_size,3))\n    if model_name =='densenet121':\n        base_model=DenseNet121(include_top=False, weights='imagenet',input_shape=(image_size,image_size,3))\n    if(model_name=='inceptionv3'):\n        base_model=InceptionV3(include_top=False,weights='imagenet',input_shape=(img_size,img_size,3))\n    if(model_name=='resnet50'):\n        base_model=ResNet50(include_top=False,weights='imagenet',input_shape=(img_size,img_size,3))\n    if(model_name=='mobilenet'):\n        base_model=MobileNet(include_top=False,weights='imagenet',input_shape=(img_size,img_size,3))\n    if(model_name=='mobilenet1.0'):\n        base_model=MobileNet(include_top=False,weights='imagenet',alpha=1.0,input_shape=(img_size,img_size,3))\n    if(model_name=='xception'):\n        base_model=Xception(include_top=False,weights='imagenet',input_shape=(img_size,img_size,3))\n    return base_model","metadata":{"id":"89d1e574","execution":{"iopub.status.busy":"2023-06-17T19:28:49.351750Z","iopub.execute_input":"2023-06-17T19:28:49.352424Z","iopub.status.idle":"2023-06-17T19:28:49.364923Z","shell.execute_reply.started":"2023-06-17T19:28:49.352375Z","shell.execute_reply":"2023-06-17T19:28:49.364016Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.losses import CategoricalCrossentropy\nimport tensorflow as tf\n\ndef weighted_cross_entropy(alpha=0.62,beta=0.68):\n    def loss_function(y_true, y_pred):\n            \n        weight = tf.where(tf.math.equal(y_true,1),alpha,1.0 - alpha)\n        weight=tf.where(tf.math.equal(y_true,3),beta,weight)\n#          weight = tf.where(tf.math.logical_or(tf.math.equal(y_true,3),tf.math.equal(y_true,1)),alpha,1.0 - alpha)\n#         weight=tf.where(y_true==1,alpha,1.0-alpha)\n        loss = CategoricalCrossentropy()(y_true, y_pred)\n        weighted_loss = loss * weight\n        return weighted_loss\n\n    return loss_function\n","metadata":{"id":"AtTqXNdGDIeJ","execution":{"iopub.status.busy":"2023-06-17T19:28:49.366409Z","iopub.execute_input":"2023-06-17T19:28:49.367090Z","iopub.status.idle":"2023-06-17T19:28:49.375922Z","shell.execute_reply.started":"2023-06-17T19:28:49.367059Z","shell.execute_reply":"2023-06-17T19:28:49.375052Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def spatial_hierarchical(last3,last2,last1,output):\n    height3,width3,_ = last3.shape[1],last3.shape[2],last3.shape[3]\n    \n    height2,width2,_ = last2.shape[1],last2.shape[2],last2.shape[3]\n    height1,width1,_ = last1.shape[1],last1.shape[2],last1.shape[3]\n    \n    output=Reshape((output.shape[1]*output.shape[2],output.shape[3]))(output) #h1w1xc1\n    num_filters=last3.shape[-1]//2\n\n    input1=Conv2D(num_filters,(1,1),padding='same')(last3)  #h1xw1xc\n    input2=Conv2D(num_filters,(1,1),padding='same')(last2)  #h2xw2xc\n    input3=Conv2D(num_filters,(1,1),padding='same')(last1)  #h3xw3xc\n    \n\n    inp1=Reshape((height3*width3,num_filters))(input1) #h1w1xc\n\n    inp2=Reshape((height2*width2,num_filters))(input2) #h2w2xc\n\n    inp3=Reshape((height1*width1,num_filters))(input3) #h3w3xc\n    \n\n    k2=K.permute_dimensions(inp2,(0,2,1))  #cxh2w2\n\n    x=K.batch_dot(inp1,k2,axes=(2,1)) #h1w1xh2w2\n\n    x=Activation('softmax')(x)\n\n    x1=K.batch_dot(x,output,axes=(2,1)) #h1w1xc\n\n    k3=K.permute_dimensions(inp3,(0,2,1)) #cxh3w3\n\n    x2=K.batch_dot(inp1,k3,axes=(2,1)) #h1w1xh3w3\n    x2=Activation('softmax')(x2)\n    \n    x2=K.batch_dot(x2,output,axes=(2,1)) #h1w1xc\n\n    \n    x_final=Concatenate()([x1,x2,inp1])\n    x_final=Reshape((height3,width3,x_final.shape[-1]))(x_final)\n    x_final=Conv2D(last3.shape[-1],(1,1),padding='same')(x_final)\n    x_final=Activation('softmax')(x_final)\n    \n   \n    x_final=Add()([x_final,last3])\n    \n\n    return x_final\n","metadata":{"execution":{"iopub.status.busy":"2023-06-17T19:31:15.761879Z","iopub.execute_input":"2023-06-17T19:31:15.762229Z","iopub.status.idle":"2023-06-17T19:31:15.774974Z","shell.execute_reply.started":"2023-06-17T19:31:15.762202Z","shell.execute_reply":"2023-06-17T19:31:15.773946Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def point_att(inputs):\n    shape=K.int_shape(inputs)\n    \n    x=Conv2D(shape[-1],(1,1),padding='same')(inputs)\n    x=Activation('sigmoid')(x)\n    \n    x=Multiply()([x,inputs])\n    \n    return x","metadata":{"execution":{"iopub.status.busy":"2023-06-17T19:28:49.392616Z","iopub.execute_input":"2023-06-17T19:28:49.393269Z","iopub.status.idle":"2023-06-17T19:28:49.401847Z","shell.execute_reply.started":"2023-06-17T19:28:49.393233Z","shell.execute_reply":"2023-06-17T19:28:49.401207Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def new_model(last3,last2,last1):\n#     shape = last3\n    height,width,channels = last3.shape[1],last3.shape[2],last3.shape[3]\n    input1=Reshape((height*width,last3.shape[-1]))(last3) #h1w1xc1  (256,1024)\n\n    input2=Reshape((height*width,last2.shape[-1]))(last2) #h1w1xc2  (256,972)\n\n    input3=Reshape((height*width,last1.shape[-1]))(last1) #h1w1xc3   (256,960)\n\n    k2=K.permute_dimensions(input1,(0,2,1)) # c1xh1w1   (1024,256)\n\n    x=K.batch_dot(k2,input1,axes=(2,1))  #c1xc2   (1024,972)\n    x=Activation('softmax')(x)\n\n    x1=K.batch_dot(input1,x,axes=(2,1)) #h1w1xc1    ()\n\n    x1=Reshape((height,width,x1.shape[-1]))(x1) #h1xw1xc1\n\n    k3=K.permute_dimensions(input1,(0,2,1)) # c1xh1w1\n    \n    x2=K.batch_dot(k3,input1,axes=(2,1)) #c1xc3\n    x2=Activation('softmax')(x2)\n\n    x2=K.batch_dot(input1,x2,axes=(2,1)) #h1w1xc1\n\n    x2=Reshape((height,width,x2.shape[-1]))(x2) #h1xw1xc1\n    \n    x_final=Concatenate()([x1,x2,last3])\n   \n    x_final=Conv2D(channels,(1,1),padding='same')(x_final)\n    x_final=Activation('softmax')(x_final)\n  \n\n    return x_final","metadata":{"execution":{"iopub.status.busy":"2023-06-17T19:30:03.631887Z","iopub.execute_input":"2023-06-17T19:30:03.632262Z","iopub.status.idle":"2023-06-17T19:30:03.643693Z","shell.execute_reply.started":"2023-06-17T19:30:03.632233Z","shell.execute_reply":"2023-06-17T19:30:03.642697Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def GSAM(inputs,channel_inp):\n    shape=K.int_shape(inputs)\n    x1=AveragePooling2D(pool_size=(shape[1],shape[2]))(inputs)\n    x2=MaxPool2D(pool_size=(shape[1],shape[2]))(inputs)\n    \n    x3=AveragePooling2D(pool_size=(shape[1],shape[2]))(channel_inp)\n    x4=MaxPool2D(pool_size=(shape[1],shape[2]))(channel_inp)\n    \n    x1=Add()([x1,x3])\n    x1=Activation('sigmoid')(x1)\n    \n    x2=Add()([x2,x4])\n    x2=Activation('sigmoid')(x2)\n    \n    x_final=Concatenate()([x2,x1])\n    \n    x_final=Conv2D(shape[-1],(1,1),padding='same')(x_final)\n    x_final=Activation('sigmoid')(x_final)\n    \n    x_final=Multiply()([x_final,channel_inp])\n    \n    return x_final\n    ","metadata":{"execution":{"iopub.status.busy":"2023-06-17T19:28:49.417680Z","iopub.execute_input":"2023-06-17T19:28:49.418346Z","iopub.status.idle":"2023-06-17T19:28:49.427358Z","shell.execute_reply.started":"2023-06-17T19:28:49.418314Z","shell.execute_reply":"2023-06-17T19:28:49.426529Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"constraint=tf.keras.constraints.min_max_norm(max_value=1,min_value=0)","metadata":{"execution":{"iopub.status.busy":"2023-06-17T19:28:49.428753Z","iopub.execute_input":"2023-06-17T19:28:49.429417Z","iopub.status.idle":"2023-06-17T19:28:49.438001Z","shell.execute_reply.started":"2023-06-17T19:28:49.429371Z","shell.execute_reply":"2023-06-17T19:28:49.437321Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"class WeightedSum(layers.Layer):\n\n    def __init__(self, **kwargs):\n        super(WeightedSum, self).__init__(**kwargs)\n\n    def build(self, input_shape=1):\n        self.a = self.add_weight( name='alpha',shape=( 1, 1, 1),initializer='random_normal',dtype='float32',trainable=True,\n            constraint = constraint,)\n        self.b = self.add_weight(name='beta',shape=( 1, 1, 1),initializer='random_normal',dtype='float32',trainable=True,constraint = constraint,)\n        \n#         self.c = self.add_weight(name='gamma',shape=( 1, 1, 1),initializer='random_normal',dtype='float32',trainable=True,constraint = constraint,)\n        super(WeightedSum, self).build(input_shape)\n\n    def call(self, model_outputs):\n#         return tf.multiply(model_outputs[0],self.a) + tf.multiply(model_outputs[1], self.b) + tf.multiply(model_outputs[2], self.c)\n        return tf.multiply(model_outputs[0],self.a) + tf.multiply(model_outputs[1], self.b) \n","metadata":{"execution":{"iopub.status.busy":"2023-06-17T19:28:49.439343Z","iopub.execute_input":"2023-06-17T19:28:49.440005Z","iopub.status.idle":"2023-06-17T19:28:49.449031Z","shell.execute_reply.started":"2023-06-17T19:28:49.439975Z","shell.execute_reply":"2023-06-17T19:28:49.448367Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def rotateToAttend(input_feature):\n  shape = K.int_shape(input_feature)\n  # HxwxC\n  permute_1 =tf.keras.layers.Permute((3,2,1),input_shape=(shape[1],shape[2],shape[3]))(input_feature) \n  #  cxwxh\n  x1 = Lambda(lambda x: K.mean(x,axis=-1,keepdims=True))(permute_1)\n  x2 = Lambda(lambda x: K.max(x,axis=-1,keepdims=True))(permute_1)\n  x3 = tf.keras.layers.Concatenate(axis=-1)([x1, x2])\n  x = Conv2D(1,1, padding='same', dilation_rate=(1, 1)) (x1)\n  x = tf.keras.layers.BatchNormalization(epsilon=1e-5, momentum=0.01)(x)\n  x = tf.keras.activations.sigmoid(x)  \n  x = tf.keras.layers.Multiply()([x,permute_1])\n  F1 = tf.keras.layers.Permute((3,2,1),input_shape=(shape[1],shape[2],shape[3]))(x)\n\n  permute_2 = tf.keras.layers.Permute((1,3,2),input_shape=(shape[1],shape[2],shape[3]))(input_feature)\n  x1 = Lambda(lambda x: K.mean(x,axis=-1,keepdims=True))(permute_2)\n  x2 = Lambda(lambda x: K.max(x,axis=-1,keepdims=True))(permute_2)\n  x3 = tf.keras.layers.Concatenate(axis=-1)([x1, x2])\n  x = Conv2D(1,1, padding='same', dilation_rate=(1, 1)) (x1)\n  x = tf.keras.layers.BatchNormalization(epsilon=1e-5, momentum=0.01)(x)\n  x = tf.keras.activations.sigmoid(x)  \n  x = tf.keras.layers.Multiply()([x,permute_2])\n  F2 = tf.keras.layers.Permute((1,3,2),input_shape=(shape[1],shape[2],shape[3]))(x)\n\n\n  permute_3 = input_feature\n  x1 = Lambda(lambda x: K.mean(x,axis=-1,keepdims=True))(permute_3)\n  x2 = Lambda(lambda x: K.max(x,axis=-1,keepdims=True))(permute_3)\n  x3 = tf.keras.layers.Concatenate(axis=-1)([x1, x2])\n  x = Conv2D(1,1, padding='same', dilation_rate=(1, 1)) (x1)\n  x = tf.keras.layers.BatchNormalization(epsilon=1e-5, momentum=0.01)(x)\n  x = tf.keras.activations.sigmoid(x)  \n  F3 = tf.keras.layers.Multiply()([x,permute_3])\n\n  attend_feature = tf.keras.layers.Average()([F1, F2, F3])\n  return attend_feature","metadata":{"id":"LXy-hSA6BjnY","execution":{"iopub.status.busy":"2023-06-17T19:28:49.450439Z","iopub.execute_input":"2023-06-17T19:28:49.451095Z","iopub.status.idle":"2023-06-17T19:28:49.467470Z","shell.execute_reply.started":"2023-06-17T19:28:49.451064Z","shell.execute_reply":"2023-06-17T19:28:49.466640Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def train_model(model,image_size,batch_size,save_name,lr1,lr2,Epochs1,Epochs2):\n\n    train_dir_fold='/kaggle/working/ddr/train'\n    val_dir_fold='/kaggle/working/ddr/validation'\n\n    train_num,valid_num=6260,2503 \n\n    train=ImageDataGenerator(rescale=1./255,horizontal_flip=True,vertical_flip=True,rotation_range=90)     \n\n    valid = ImageDataGenerator(rescale=1./255)\n      \n    train_data = train.flow_from_directory(train_dir_fold, target_size=(image_size, image_size),shuffle=True,\n                                                  batch_size=batch_size)\n    val_data = valid.flow_from_directory(val_dir_fold, target_size=(image_size, image_size),shuffle=False,\n                                                 batch_size=batch_size)\n                                                  \n      \n    \n    \n    \n    lr_decay=ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=3, verbose=1)\n    save_model=ModelCheckpoint('new/'+save_name+'{epoch:02d}.h5', monitor='val_loss',save_best_only=True,mode='min')\n    \n    for layer in base_model.layers:\n         layer.trainable=False\n\n    model.compile(optimizer=Adam(learning_rate=lr1,decay=0.00001),loss='categorical_crossentropy',metrics=['accuracy'])\n    model.fit(train_data,steps_per_epoch=train_num/batch_size,validation_data=val_data,validation_steps=valid_num/batch_size,\n              epochs=Epochs1,workers=2,callbacks=[lr_decay,save_model])\n     \n    for layer in base_model.layers:\n         layer.trainable = True\n        \n    model.compile(optimizer=Adam(learning_rate=lr2,decay=0.00001),loss='categorical_crossentropy',metrics=['accuracy'])\n    history=model.fit(train_data,steps_per_epoch=train_num/batch_size,validation_data=val_data,\n                      validation_steps=valid_num/batch_size,epochs=Epochs2,workers=2,\n                       callbacks=[lr_decay,save_model])\n\n    return history","metadata":{"id":"7edc9257","execution":{"iopub.status.busy":"2023-06-17T19:32:24.035173Z","iopub.execute_input":"2023-06-17T19:32:24.035540Z","iopub.status.idle":"2023-06-17T19:32:24.047668Z","shell.execute_reply.started":"2023-06-17T19:32:24.035510Z","shell.execute_reply":"2023-06-17T19:32:24.046667Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications import DenseNet121\nfrom tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D, Dropout, Dense\n\nk = 5\nlr1 = 0.005\nlr2 = 0.0001\nbatch_size = 16\nimage_size = 512\nclasses = 5\n\n\nbase_model=DenseNet121(include_top=False,weights='imagenet',input_shape=(image_size,image_size,3))\nbase_in = base_model.input\nbase_out=base_model.output\n\n\nlast3 = base_model.get_layer('relu').output\nlast2 = base_model.get_layer('conv5_block16_1_relu').output\nlast1 = base_model.get_layer('conv5_block15_0_relu').output\n\n# last3 = base_model.get_layer('conv5_block3_out').output\n# last2 = base_model.get_layer('conv5_block2_out').output\n# last1 = base_model.get_layer('conv5_block1_out').output\n\n\n# last3=Conv2D(base_out.shape[-1],(1,1),padding='same')(last3)\n# last2=Conv2D(base_out.shape[-1]//2,(1,1),padding='same')(last2)\n# last1=Conv2D(base_out.shape[-1]//2,(1,1),padding='same')(last1)\n\n# x=Concatenate()([last3,last2,last1])\n\n\n# x1 = globalchannelattention(base_out)\nx1 = new_model(last3,last2,last1)\nx2 = spatial_hierarchical(last3,last2,last1,x1)\n# x = globalchannelattention(compress)\n# x2 = SelfAttention(compress, 2)\n\n# x2=spatial_attention(base_out)\n\n\n# x1=rotateToAttend(base_out)\n# x2=point_att(base_out)\n# x3=attention(base_out)\n\n# x=Add()([x1,x2,x3])\n# x=WeightedSum()([x1,x2,x3])\n\nx=Concatenate()([x1,x2])\n\n# x=Add()([last3,x1])\n\n# x=Multiply()([x1,last3])\n# x=WeightedSum()([last3,x])\n\n\nx = GlobalAveragePooling2D()(x)\nout = Dense(classes, activation='softmax')(x)\n\nparallel_model = Model(base_in, out)\nparallel_model.summary()\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"50a26fb8","outputId":"665a44d8-bfa7-44e2-a8c1-9190784f1f9d","scrolled":true,"execution":{"iopub.status.busy":"2023-06-17T19:31:18.582724Z","iopub.execute_input":"2023-06-17T19:31:18.583171Z","iopub.status.idle":"2023-06-17T19:31:23.063314Z","shell.execute_reply.started":"2023-06-17T19:31:18.583125Z","shell.execute_reply":"2023-06-17T19:31:23.062530Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_4 (InputLayer)           [(None, 512, 512, 3  0           []                               \n                                )]                                                                \n                                                                                                  \n zero_padding2d_6 (ZeroPadding2  (None, 518, 518, 3)  0          ['input_4[0][0]']                \n D)                                                                                               \n                                                                                                  \n conv1/conv (Conv2D)            (None, 256, 256, 64  9408        ['zero_padding2d_6[0][0]']       \n                                )                                                                 \n                                                                                                  \n conv1/bn (BatchNormalization)  (None, 256, 256, 64  256         ['conv1/conv[0][0]']             \n                                )                                                                 \n                                                                                                  \n conv1/relu (Activation)        (None, 256, 256, 64  0           ['conv1/bn[0][0]']               \n                                )                                                                 \n                                                                                                  \n zero_padding2d_7 (ZeroPadding2  (None, 258, 258, 64  0          ['conv1/relu[0][0]']             \n D)                             )                                                                 \n                                                                                                  \n pool1 (MaxPooling2D)           (None, 128, 128, 64  0           ['zero_padding2d_7[0][0]']       \n                                )                                                                 \n                                                                                                  \n conv2_block1_0_bn (BatchNormal  (None, 128, 128, 64  256        ['pool1[0][0]']                  \n ization)                       )                                                                 \n                                                                                                  \n conv2_block1_0_relu (Activatio  (None, 128, 128, 64  0          ['conv2_block1_0_bn[0][0]']      \n n)                             )                                                                 \n                                                                                                  \n conv2_block1_1_conv (Conv2D)   (None, 128, 128, 12  8192        ['conv2_block1_0_relu[0][0]']    \n                                8)                                                                \n                                                                                                  \n conv2_block1_1_bn (BatchNormal  (None, 128, 128, 12  512        ['conv2_block1_1_conv[0][0]']    \n ization)                       8)                                                                \n                                                                                                  \n conv2_block1_1_relu (Activatio  (None, 128, 128, 12  0          ['conv2_block1_1_bn[0][0]']      \n n)                             8)                                                                \n                                                                                                  \n conv2_block1_2_conv (Conv2D)   (None, 128, 128, 32  36864       ['conv2_block1_1_relu[0][0]']    \n                                )                                                                 \n                                                                                                  \n conv2_block1_concat (Concatena  (None, 128, 128, 96  0          ['pool1[0][0]',                  \n te)                            )                                 'conv2_block1_2_conv[0][0]']    \n                                                                                                  \n conv2_block2_0_bn (BatchNormal  (None, 128, 128, 96  384        ['conv2_block1_concat[0][0]']    \n ization)                       )                                                                 \n                                                                                                  \n conv2_block2_0_relu (Activatio  (None, 128, 128, 96  0          ['conv2_block2_0_bn[0][0]']      \n n)                             )                                                                 \n                                                                                                  \n conv2_block2_1_conv (Conv2D)   (None, 128, 128, 12  12288       ['conv2_block2_0_relu[0][0]']    \n                                8)                                                                \n                                                                                                  \n conv2_block2_1_bn (BatchNormal  (None, 128, 128, 12  512        ['conv2_block2_1_conv[0][0]']    \n ization)                       8)                                                                \n                                                                                                  \n conv2_block2_1_relu (Activatio  (None, 128, 128, 12  0          ['conv2_block2_1_bn[0][0]']      \n n)                             8)                                                                \n                                                                                                  \n conv2_block2_2_conv (Conv2D)   (None, 128, 128, 32  36864       ['conv2_block2_1_relu[0][0]']    \n                                )                                                                 \n                                                                                                  \n conv2_block2_concat (Concatena  (None, 128, 128, 12  0          ['conv2_block1_concat[0][0]',    \n te)                            8)                                'conv2_block2_2_conv[0][0]']    \n                                                                                                  \n conv2_block3_0_bn (BatchNormal  (None, 128, 128, 12  512        ['conv2_block2_concat[0][0]']    \n ization)                       8)                                                                \n                                                                                                  \n conv2_block3_0_relu (Activatio  (None, 128, 128, 12  0          ['conv2_block3_0_bn[0][0]']      \n n)                             8)                                                                \n                                                                                                  \n conv2_block3_1_conv (Conv2D)   (None, 128, 128, 12  16384       ['conv2_block3_0_relu[0][0]']    \n                                8)                                                                \n                                                                                                  \n conv2_block3_1_bn (BatchNormal  (None, 128, 128, 12  512        ['conv2_block3_1_conv[0][0]']    \n ization)                       8)                                                                \n                                                                                                  \n conv2_block3_1_relu (Activatio  (None, 128, 128, 12  0          ['conv2_block3_1_bn[0][0]']      \n n)                             8)                                                                \n                                                                                                  \n conv2_block3_2_conv (Conv2D)   (None, 128, 128, 32  36864       ['conv2_block3_1_relu[0][0]']    \n                                )                                                                 \n                                                                                                  \n conv2_block3_concat (Concatena  (None, 128, 128, 16  0          ['conv2_block2_concat[0][0]',    \n te)                            0)                                'conv2_block3_2_conv[0][0]']    \n                                                                                                  \n conv2_block4_0_bn (BatchNormal  (None, 128, 128, 16  640        ['conv2_block3_concat[0][0]']    \n ization)                       0)                                                                \n                                                                                                  \n conv2_block4_0_relu (Activatio  (None, 128, 128, 16  0          ['conv2_block4_0_bn[0][0]']      \n n)                             0)                                                                \n                                                                                                  \n conv2_block4_1_conv (Conv2D)   (None, 128, 128, 12  20480       ['conv2_block4_0_relu[0][0]']    \n                                8)                                                                \n                                                                                                  \n conv2_block4_1_bn (BatchNormal  (None, 128, 128, 12  512        ['conv2_block4_1_conv[0][0]']    \n ization)                       8)                                                                \n                                                                                                  \n conv2_block4_1_relu (Activatio  (None, 128, 128, 12  0          ['conv2_block4_1_bn[0][0]']      \n n)                             8)                                                                \n                                                                                                  \n conv2_block4_2_conv (Conv2D)   (None, 128, 128, 32  36864       ['conv2_block4_1_relu[0][0]']    \n                                )                                                                 \n                                                                                                  \n conv2_block4_concat (Concatena  (None, 128, 128, 19  0          ['conv2_block3_concat[0][0]',    \n te)                            2)                                'conv2_block4_2_conv[0][0]']    \n                                                                                                  \n conv2_block5_0_bn (BatchNormal  (None, 128, 128, 19  768        ['conv2_block4_concat[0][0]']    \n ization)                       2)                                                                \n                                                                                                  \n conv2_block5_0_relu (Activatio  (None, 128, 128, 19  0          ['conv2_block5_0_bn[0][0]']      \n n)                             2)                                                                \n                                                                                                  \n conv2_block5_1_conv (Conv2D)   (None, 128, 128, 12  24576       ['conv2_block5_0_relu[0][0]']    \n                                8)                                                                \n                                                                                                  \n conv2_block5_1_bn (BatchNormal  (None, 128, 128, 12  512        ['conv2_block5_1_conv[0][0]']    \n ization)                       8)                                                                \n                                                                                                  \n conv2_block5_1_relu (Activatio  (None, 128, 128, 12  0          ['conv2_block5_1_bn[0][0]']      \n n)                             8)                                                                \n                                                                                                  \n conv2_block5_2_conv (Conv2D)   (None, 128, 128, 32  36864       ['conv2_block5_1_relu[0][0]']    \n                                )                                                                 \n                                                                                                  \n conv2_block5_concat (Concatena  (None, 128, 128, 22  0          ['conv2_block4_concat[0][0]',    \n te)                            4)                                'conv2_block5_2_conv[0][0]']    \n                                                                                                  \n conv2_block6_0_bn (BatchNormal  (None, 128, 128, 22  896        ['conv2_block5_concat[0][0]']    \n ization)                       4)                                                                \n                                                                                                  \n conv2_block6_0_relu (Activatio  (None, 128, 128, 22  0          ['conv2_block6_0_bn[0][0]']      \n n)                             4)                                                                \n                                                                                                  \n conv2_block6_1_conv (Conv2D)   (None, 128, 128, 12  28672       ['conv2_block6_0_relu[0][0]']    \n                                8)                                                                \n                                                                                                  \n conv2_block6_1_bn (BatchNormal  (None, 128, 128, 12  512        ['conv2_block6_1_conv[0][0]']    \n ization)                       8)                                                                \n                                                                                                  \n conv2_block6_1_relu (Activatio  (None, 128, 128, 12  0          ['conv2_block6_1_bn[0][0]']      \n n)                             8)                                                                \n                                                                                                  \n conv2_block6_2_conv (Conv2D)   (None, 128, 128, 32  36864       ['conv2_block6_1_relu[0][0]']    \n                                )                                                                 \n                                                                                                  \n conv2_block6_concat (Concatena  (None, 128, 128, 25  0          ['conv2_block5_concat[0][0]',    \n te)                            6)                                'conv2_block6_2_conv[0][0]']    \n                                                                                                  \n pool2_bn (BatchNormalization)  (None, 128, 128, 25  1024        ['conv2_block6_concat[0][0]']    \n                                6)                                                                \n                                                                                                  \n pool2_relu (Activation)        (None, 128, 128, 25  0           ['pool2_bn[0][0]']               \n                                6)                                                                \n                                                                                                  \n pool2_conv (Conv2D)            (None, 128, 128, 12  32768       ['pool2_relu[0][0]']             \n                                8)                                                                \n                                                                                                  \n pool2_pool (AveragePooling2D)  (None, 64, 64, 128)  0           ['pool2_conv[0][0]']             \n                                                                                                  \n conv3_block1_0_bn (BatchNormal  (None, 64, 64, 128)  512        ['pool2_pool[0][0]']             \n ization)                                                                                         \n                                                                                                  \n conv3_block1_0_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block1_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block1_1_conv (Conv2D)   (None, 64, 64, 128)  16384       ['conv3_block1_0_relu[0][0]']    \n                                                                                                  \n conv3_block1_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block1_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block1_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block1_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block1_2_conv (Conv2D)   (None, 64, 64, 32)   36864       ['conv3_block1_1_relu[0][0]']    \n                                                                                                  \n conv3_block1_concat (Concatena  (None, 64, 64, 160)  0          ['pool2_pool[0][0]',             \n te)                                                              'conv3_block1_2_conv[0][0]']    \n                                                                                                  \n conv3_block2_0_bn (BatchNormal  (None, 64, 64, 160)  640        ['conv3_block1_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block2_0_relu (Activatio  (None, 64, 64, 160)  0          ['conv3_block2_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block2_1_conv (Conv2D)   (None, 64, 64, 128)  20480       ['conv3_block2_0_relu[0][0]']    \n                                                                                                  \n conv3_block2_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block2_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block2_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block2_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block2_2_conv (Conv2D)   (None, 64, 64, 32)   36864       ['conv3_block2_1_relu[0][0]']    \n                                                                                                  \n conv3_block2_concat (Concatena  (None, 64, 64, 192)  0          ['conv3_block1_concat[0][0]',    \n te)                                                              'conv3_block2_2_conv[0][0]']    \n                                                                                                  \n conv3_block3_0_bn (BatchNormal  (None, 64, 64, 192)  768        ['conv3_block2_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block3_0_relu (Activatio  (None, 64, 64, 192)  0          ['conv3_block3_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block3_1_conv (Conv2D)   (None, 64, 64, 128)  24576       ['conv3_block3_0_relu[0][0]']    \n                                                                                                  \n conv3_block3_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block3_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block3_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block3_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block3_2_conv (Conv2D)   (None, 64, 64, 32)   36864       ['conv3_block3_1_relu[0][0]']    \n                                                                                                  \n conv3_block3_concat (Concatena  (None, 64, 64, 224)  0          ['conv3_block2_concat[0][0]',    \n te)                                                              'conv3_block3_2_conv[0][0]']    \n                                                                                                  \n conv3_block4_0_bn (BatchNormal  (None, 64, 64, 224)  896        ['conv3_block3_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block4_0_relu (Activatio  (None, 64, 64, 224)  0          ['conv3_block4_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block4_1_conv (Conv2D)   (None, 64, 64, 128)  28672       ['conv3_block4_0_relu[0][0]']    \n                                                                                                  \n conv3_block4_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block4_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block4_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block4_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block4_2_conv (Conv2D)   (None, 64, 64, 32)   36864       ['conv3_block4_1_relu[0][0]']    \n                                                                                                  \n conv3_block4_concat (Concatena  (None, 64, 64, 256)  0          ['conv3_block3_concat[0][0]',    \n te)                                                              'conv3_block4_2_conv[0][0]']    \n                                                                                                  \n conv3_block5_0_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv3_block4_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block5_0_relu (Activatio  (None, 64, 64, 256)  0          ['conv3_block5_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block5_1_conv (Conv2D)   (None, 64, 64, 128)  32768       ['conv3_block5_0_relu[0][0]']    \n                                                                                                  \n conv3_block5_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block5_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block5_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block5_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block5_2_conv (Conv2D)   (None, 64, 64, 32)   36864       ['conv3_block5_1_relu[0][0]']    \n                                                                                                  \n conv3_block5_concat (Concatena  (None, 64, 64, 288)  0          ['conv3_block4_concat[0][0]',    \n te)                                                              'conv3_block5_2_conv[0][0]']    \n                                                                                                  \n conv3_block6_0_bn (BatchNormal  (None, 64, 64, 288)  1152       ['conv3_block5_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block6_0_relu (Activatio  (None, 64, 64, 288)  0          ['conv3_block6_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block6_1_conv (Conv2D)   (None, 64, 64, 128)  36864       ['conv3_block6_0_relu[0][0]']    \n                                                                                                  \n conv3_block6_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block6_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block6_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block6_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block6_2_conv (Conv2D)   (None, 64, 64, 32)   36864       ['conv3_block6_1_relu[0][0]']    \n                                                                                                  \n conv3_block6_concat (Concatena  (None, 64, 64, 320)  0          ['conv3_block5_concat[0][0]',    \n te)                                                              'conv3_block6_2_conv[0][0]']    \n                                                                                                  \n conv3_block7_0_bn (BatchNormal  (None, 64, 64, 320)  1280       ['conv3_block6_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block7_0_relu (Activatio  (None, 64, 64, 320)  0          ['conv3_block7_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block7_1_conv (Conv2D)   (None, 64, 64, 128)  40960       ['conv3_block7_0_relu[0][0]']    \n                                                                                                  \n conv3_block7_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block7_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block7_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block7_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block7_2_conv (Conv2D)   (None, 64, 64, 32)   36864       ['conv3_block7_1_relu[0][0]']    \n                                                                                                  \n conv3_block7_concat (Concatena  (None, 64, 64, 352)  0          ['conv3_block6_concat[0][0]',    \n te)                                                              'conv3_block7_2_conv[0][0]']    \n                                                                                                  \n conv3_block8_0_bn (BatchNormal  (None, 64, 64, 352)  1408       ['conv3_block7_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block8_0_relu (Activatio  (None, 64, 64, 352)  0          ['conv3_block8_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block8_1_conv (Conv2D)   (None, 64, 64, 128)  45056       ['conv3_block8_0_relu[0][0]']    \n                                                                                                  \n conv3_block8_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block8_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block8_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block8_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block8_2_conv (Conv2D)   (None, 64, 64, 32)   36864       ['conv3_block8_1_relu[0][0]']    \n                                                                                                  \n conv3_block8_concat (Concatena  (None, 64, 64, 384)  0          ['conv3_block7_concat[0][0]',    \n te)                                                              'conv3_block8_2_conv[0][0]']    \n                                                                                                  \n conv3_block9_0_bn (BatchNormal  (None, 64, 64, 384)  1536       ['conv3_block8_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block9_0_relu (Activatio  (None, 64, 64, 384)  0          ['conv3_block9_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block9_1_conv (Conv2D)   (None, 64, 64, 128)  49152       ['conv3_block9_0_relu[0][0]']    \n                                                                                                  \n conv3_block9_1_bn (BatchNormal  (None, 64, 64, 128)  512        ['conv3_block9_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block9_1_relu (Activatio  (None, 64, 64, 128)  0          ['conv3_block9_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block9_2_conv (Conv2D)   (None, 64, 64, 32)   36864       ['conv3_block9_1_relu[0][0]']    \n                                                                                                  \n conv3_block9_concat (Concatena  (None, 64, 64, 416)  0          ['conv3_block8_concat[0][0]',    \n te)                                                              'conv3_block9_2_conv[0][0]']    \n                                                                                                  \n conv3_block10_0_bn (BatchNorma  (None, 64, 64, 416)  1664       ['conv3_block9_concat[0][0]']    \n lization)                                                                                        \n                                                                                                  \n conv3_block10_0_relu (Activati  (None, 64, 64, 416)  0          ['conv3_block10_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv3_block10_1_conv (Conv2D)  (None, 64, 64, 128)  53248       ['conv3_block10_0_relu[0][0]']   \n                                                                                                  \n conv3_block10_1_bn (BatchNorma  (None, 64, 64, 128)  512        ['conv3_block10_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv3_block10_1_relu (Activati  (None, 64, 64, 128)  0          ['conv3_block10_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv3_block10_2_conv (Conv2D)  (None, 64, 64, 32)   36864       ['conv3_block10_1_relu[0][0]']   \n                                                                                                  \n conv3_block10_concat (Concaten  (None, 64, 64, 448)  0          ['conv3_block9_concat[0][0]',    \n ate)                                                             'conv3_block10_2_conv[0][0]']   \n                                                                                                  \n conv3_block11_0_bn (BatchNorma  (None, 64, 64, 448)  1792       ['conv3_block10_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv3_block11_0_relu (Activati  (None, 64, 64, 448)  0          ['conv3_block11_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv3_block11_1_conv (Conv2D)  (None, 64, 64, 128)  57344       ['conv3_block11_0_relu[0][0]']   \n                                                                                                  \n conv3_block11_1_bn (BatchNorma  (None, 64, 64, 128)  512        ['conv3_block11_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv3_block11_1_relu (Activati  (None, 64, 64, 128)  0          ['conv3_block11_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv3_block11_2_conv (Conv2D)  (None, 64, 64, 32)   36864       ['conv3_block11_1_relu[0][0]']   \n                                                                                                  \n conv3_block11_concat (Concaten  (None, 64, 64, 480)  0          ['conv3_block10_concat[0][0]',   \n ate)                                                             'conv3_block11_2_conv[0][0]']   \n                                                                                                  \n conv3_block12_0_bn (BatchNorma  (None, 64, 64, 480)  1920       ['conv3_block11_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv3_block12_0_relu (Activati  (None, 64, 64, 480)  0          ['conv3_block12_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv3_block12_1_conv (Conv2D)  (None, 64, 64, 128)  61440       ['conv3_block12_0_relu[0][0]']   \n                                                                                                  \n conv3_block12_1_bn (BatchNorma  (None, 64, 64, 128)  512        ['conv3_block12_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv3_block12_1_relu (Activati  (None, 64, 64, 128)  0          ['conv3_block12_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv3_block12_2_conv (Conv2D)  (None, 64, 64, 32)   36864       ['conv3_block12_1_relu[0][0]']   \n                                                                                                  \n conv3_block12_concat (Concaten  (None, 64, 64, 512)  0          ['conv3_block11_concat[0][0]',   \n ate)                                                             'conv3_block12_2_conv[0][0]']   \n                                                                                                  \n pool3_bn (BatchNormalization)  (None, 64, 64, 512)  2048        ['conv3_block12_concat[0][0]']   \n                                                                                                  \n pool3_relu (Activation)        (None, 64, 64, 512)  0           ['pool3_bn[0][0]']               \n                                                                                                  \n pool3_conv (Conv2D)            (None, 64, 64, 256)  131072      ['pool3_relu[0][0]']             \n                                                                                                  \n pool3_pool (AveragePooling2D)  (None, 32, 32, 256)  0           ['pool3_conv[0][0]']             \n                                                                                                  \n conv4_block1_0_bn (BatchNormal  (None, 32, 32, 256)  1024       ['pool3_pool[0][0]']             \n ization)                                                                                         \n                                                                                                  \n conv4_block1_0_relu (Activatio  (None, 32, 32, 256)  0          ['conv4_block1_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block1_1_conv (Conv2D)   (None, 32, 32, 128)  32768       ['conv4_block1_0_relu[0][0]']    \n                                                                                                  \n conv4_block1_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv4_block1_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block1_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv4_block1_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block1_2_conv (Conv2D)   (None, 32, 32, 32)   36864       ['conv4_block1_1_relu[0][0]']    \n                                                                                                  \n conv4_block1_concat (Concatena  (None, 32, 32, 288)  0          ['pool3_pool[0][0]',             \n te)                                                              'conv4_block1_2_conv[0][0]']    \n                                                                                                  \n conv4_block2_0_bn (BatchNormal  (None, 32, 32, 288)  1152       ['conv4_block1_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block2_0_relu (Activatio  (None, 32, 32, 288)  0          ['conv4_block2_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block2_1_conv (Conv2D)   (None, 32, 32, 128)  36864       ['conv4_block2_0_relu[0][0]']    \n                                                                                                  \n conv4_block2_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv4_block2_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block2_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv4_block2_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block2_2_conv (Conv2D)   (None, 32, 32, 32)   36864       ['conv4_block2_1_relu[0][0]']    \n                                                                                                  \n conv4_block2_concat (Concatena  (None, 32, 32, 320)  0          ['conv4_block1_concat[0][0]',    \n te)                                                              'conv4_block2_2_conv[0][0]']    \n                                                                                                  \n conv4_block3_0_bn (BatchNormal  (None, 32, 32, 320)  1280       ['conv4_block2_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block3_0_relu (Activatio  (None, 32, 32, 320)  0          ['conv4_block3_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block3_1_conv (Conv2D)   (None, 32, 32, 128)  40960       ['conv4_block3_0_relu[0][0]']    \n                                                                                                  \n conv4_block3_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv4_block3_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block3_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv4_block3_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block3_2_conv (Conv2D)   (None, 32, 32, 32)   36864       ['conv4_block3_1_relu[0][0]']    \n                                                                                                  \n conv4_block3_concat (Concatena  (None, 32, 32, 352)  0          ['conv4_block2_concat[0][0]',    \n te)                                                              'conv4_block3_2_conv[0][0]']    \n                                                                                                  \n conv4_block4_0_bn (BatchNormal  (None, 32, 32, 352)  1408       ['conv4_block3_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block4_0_relu (Activatio  (None, 32, 32, 352)  0          ['conv4_block4_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block4_1_conv (Conv2D)   (None, 32, 32, 128)  45056       ['conv4_block4_0_relu[0][0]']    \n                                                                                                  \n conv4_block4_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv4_block4_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block4_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv4_block4_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block4_2_conv (Conv2D)   (None, 32, 32, 32)   36864       ['conv4_block4_1_relu[0][0]']    \n                                                                                                  \n conv4_block4_concat (Concatena  (None, 32, 32, 384)  0          ['conv4_block3_concat[0][0]',    \n te)                                                              'conv4_block4_2_conv[0][0]']    \n                                                                                                  \n conv4_block5_0_bn (BatchNormal  (None, 32, 32, 384)  1536       ['conv4_block4_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block5_0_relu (Activatio  (None, 32, 32, 384)  0          ['conv4_block5_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block5_1_conv (Conv2D)   (None, 32, 32, 128)  49152       ['conv4_block5_0_relu[0][0]']    \n                                                                                                  \n conv4_block5_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv4_block5_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block5_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv4_block5_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block5_2_conv (Conv2D)   (None, 32, 32, 32)   36864       ['conv4_block5_1_relu[0][0]']    \n                                                                                                  \n conv4_block5_concat (Concatena  (None, 32, 32, 416)  0          ['conv4_block4_concat[0][0]',    \n te)                                                              'conv4_block5_2_conv[0][0]']    \n                                                                                                  \n conv4_block6_0_bn (BatchNormal  (None, 32, 32, 416)  1664       ['conv4_block5_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block6_0_relu (Activatio  (None, 32, 32, 416)  0          ['conv4_block6_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block6_1_conv (Conv2D)   (None, 32, 32, 128)  53248       ['conv4_block6_0_relu[0][0]']    \n                                                                                                  \n conv4_block6_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv4_block6_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block6_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv4_block6_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block6_2_conv (Conv2D)   (None, 32, 32, 32)   36864       ['conv4_block6_1_relu[0][0]']    \n                                                                                                  \n conv4_block6_concat (Concatena  (None, 32, 32, 448)  0          ['conv4_block5_concat[0][0]',    \n te)                                                              'conv4_block6_2_conv[0][0]']    \n                                                                                                  \n conv4_block7_0_bn (BatchNormal  (None, 32, 32, 448)  1792       ['conv4_block6_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block7_0_relu (Activatio  (None, 32, 32, 448)  0          ['conv4_block7_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block7_1_conv (Conv2D)   (None, 32, 32, 128)  57344       ['conv4_block7_0_relu[0][0]']    \n                                                                                                  \n conv4_block7_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv4_block7_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block7_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv4_block7_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block7_2_conv (Conv2D)   (None, 32, 32, 32)   36864       ['conv4_block7_1_relu[0][0]']    \n                                                                                                  \n conv4_block7_concat (Concatena  (None, 32, 32, 480)  0          ['conv4_block6_concat[0][0]',    \n te)                                                              'conv4_block7_2_conv[0][0]']    \n                                                                                                  \n conv4_block8_0_bn (BatchNormal  (None, 32, 32, 480)  1920       ['conv4_block7_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block8_0_relu (Activatio  (None, 32, 32, 480)  0          ['conv4_block8_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block8_1_conv (Conv2D)   (None, 32, 32, 128)  61440       ['conv4_block8_0_relu[0][0]']    \n                                                                                                  \n conv4_block8_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv4_block8_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block8_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv4_block8_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block8_2_conv (Conv2D)   (None, 32, 32, 32)   36864       ['conv4_block8_1_relu[0][0]']    \n                                                                                                  \n conv4_block8_concat (Concatena  (None, 32, 32, 512)  0          ['conv4_block7_concat[0][0]',    \n te)                                                              'conv4_block8_2_conv[0][0]']    \n                                                                                                  \n conv4_block9_0_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv4_block8_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block9_0_relu (Activatio  (None, 32, 32, 512)  0          ['conv4_block9_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block9_1_conv (Conv2D)   (None, 32, 32, 128)  65536       ['conv4_block9_0_relu[0][0]']    \n                                                                                                  \n conv4_block9_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv4_block9_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block9_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv4_block9_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block9_2_conv (Conv2D)   (None, 32, 32, 32)   36864       ['conv4_block9_1_relu[0][0]']    \n                                                                                                  \n conv4_block9_concat (Concatena  (None, 32, 32, 544)  0          ['conv4_block8_concat[0][0]',    \n te)                                                              'conv4_block9_2_conv[0][0]']    \n                                                                                                  \n conv4_block10_0_bn (BatchNorma  (None, 32, 32, 544)  2176       ['conv4_block9_concat[0][0]']    \n lization)                                                                                        \n                                                                                                  \n conv4_block10_0_relu (Activati  (None, 32, 32, 544)  0          ['conv4_block10_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block10_1_conv (Conv2D)  (None, 32, 32, 128)  69632       ['conv4_block10_0_relu[0][0]']   \n                                                                                                  \n conv4_block10_1_bn (BatchNorma  (None, 32, 32, 128)  512        ['conv4_block10_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block10_1_relu (Activati  (None, 32, 32, 128)  0          ['conv4_block10_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block10_2_conv (Conv2D)  (None, 32, 32, 32)   36864       ['conv4_block10_1_relu[0][0]']   \n                                                                                                  \n conv4_block10_concat (Concaten  (None, 32, 32, 576)  0          ['conv4_block9_concat[0][0]',    \n ate)                                                             'conv4_block10_2_conv[0][0]']   \n                                                                                                  \n conv4_block11_0_bn (BatchNorma  (None, 32, 32, 576)  2304       ['conv4_block10_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block11_0_relu (Activati  (None, 32, 32, 576)  0          ['conv4_block11_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block11_1_conv (Conv2D)  (None, 32, 32, 128)  73728       ['conv4_block11_0_relu[0][0]']   \n                                                                                                  \n conv4_block11_1_bn (BatchNorma  (None, 32, 32, 128)  512        ['conv4_block11_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block11_1_relu (Activati  (None, 32, 32, 128)  0          ['conv4_block11_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block11_2_conv (Conv2D)  (None, 32, 32, 32)   36864       ['conv4_block11_1_relu[0][0]']   \n                                                                                                  \n conv4_block11_concat (Concaten  (None, 32, 32, 608)  0          ['conv4_block10_concat[0][0]',   \n ate)                                                             'conv4_block11_2_conv[0][0]']   \n                                                                                                  \n conv4_block12_0_bn (BatchNorma  (None, 32, 32, 608)  2432       ['conv4_block11_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block12_0_relu (Activati  (None, 32, 32, 608)  0          ['conv4_block12_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block12_1_conv (Conv2D)  (None, 32, 32, 128)  77824       ['conv4_block12_0_relu[0][0]']   \n                                                                                                  \n conv4_block12_1_bn (BatchNorma  (None, 32, 32, 128)  512        ['conv4_block12_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block12_1_relu (Activati  (None, 32, 32, 128)  0          ['conv4_block12_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block12_2_conv (Conv2D)  (None, 32, 32, 32)   36864       ['conv4_block12_1_relu[0][0]']   \n                                                                                                  \n conv4_block12_concat (Concaten  (None, 32, 32, 640)  0          ['conv4_block11_concat[0][0]',   \n ate)                                                             'conv4_block12_2_conv[0][0]']   \n                                                                                                  \n conv4_block13_0_bn (BatchNorma  (None, 32, 32, 640)  2560       ['conv4_block12_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block13_0_relu (Activati  (None, 32, 32, 640)  0          ['conv4_block13_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block13_1_conv (Conv2D)  (None, 32, 32, 128)  81920       ['conv4_block13_0_relu[0][0]']   \n                                                                                                  \n conv4_block13_1_bn (BatchNorma  (None, 32, 32, 128)  512        ['conv4_block13_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block13_1_relu (Activati  (None, 32, 32, 128)  0          ['conv4_block13_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block13_2_conv (Conv2D)  (None, 32, 32, 32)   36864       ['conv4_block13_1_relu[0][0]']   \n                                                                                                  \n conv4_block13_concat (Concaten  (None, 32, 32, 672)  0          ['conv4_block12_concat[0][0]',   \n ate)                                                             'conv4_block13_2_conv[0][0]']   \n                                                                                                  \n conv4_block14_0_bn (BatchNorma  (None, 32, 32, 672)  2688       ['conv4_block13_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block14_0_relu (Activati  (None, 32, 32, 672)  0          ['conv4_block14_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block14_1_conv (Conv2D)  (None, 32, 32, 128)  86016       ['conv4_block14_0_relu[0][0]']   \n                                                                                                  \n conv4_block14_1_bn (BatchNorma  (None, 32, 32, 128)  512        ['conv4_block14_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block14_1_relu (Activati  (None, 32, 32, 128)  0          ['conv4_block14_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block14_2_conv (Conv2D)  (None, 32, 32, 32)   36864       ['conv4_block14_1_relu[0][0]']   \n                                                                                                  \n conv4_block14_concat (Concaten  (None, 32, 32, 704)  0          ['conv4_block13_concat[0][0]',   \n ate)                                                             'conv4_block14_2_conv[0][0]']   \n                                                                                                  \n conv4_block15_0_bn (BatchNorma  (None, 32, 32, 704)  2816       ['conv4_block14_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block15_0_relu (Activati  (None, 32, 32, 704)  0          ['conv4_block15_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block15_1_conv (Conv2D)  (None, 32, 32, 128)  90112       ['conv4_block15_0_relu[0][0]']   \n                                                                                                  \n conv4_block15_1_bn (BatchNorma  (None, 32, 32, 128)  512        ['conv4_block15_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block15_1_relu (Activati  (None, 32, 32, 128)  0          ['conv4_block15_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block15_2_conv (Conv2D)  (None, 32, 32, 32)   36864       ['conv4_block15_1_relu[0][0]']   \n                                                                                                  \n conv4_block15_concat (Concaten  (None, 32, 32, 736)  0          ['conv4_block14_concat[0][0]',   \n ate)                                                             'conv4_block15_2_conv[0][0]']   \n                                                                                                  \n conv4_block16_0_bn (BatchNorma  (None, 32, 32, 736)  2944       ['conv4_block15_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block16_0_relu (Activati  (None, 32, 32, 736)  0          ['conv4_block16_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block16_1_conv (Conv2D)  (None, 32, 32, 128)  94208       ['conv4_block16_0_relu[0][0]']   \n                                                                                                  \n conv4_block16_1_bn (BatchNorma  (None, 32, 32, 128)  512        ['conv4_block16_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block16_1_relu (Activati  (None, 32, 32, 128)  0          ['conv4_block16_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block16_2_conv (Conv2D)  (None, 32, 32, 32)   36864       ['conv4_block16_1_relu[0][0]']   \n                                                                                                  \n conv4_block16_concat (Concaten  (None, 32, 32, 768)  0          ['conv4_block15_concat[0][0]',   \n ate)                                                             'conv4_block16_2_conv[0][0]']   \n                                                                                                  \n conv4_block17_0_bn (BatchNorma  (None, 32, 32, 768)  3072       ['conv4_block16_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block17_0_relu (Activati  (None, 32, 32, 768)  0          ['conv4_block17_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block17_1_conv (Conv2D)  (None, 32, 32, 128)  98304       ['conv4_block17_0_relu[0][0]']   \n                                                                                                  \n conv4_block17_1_bn (BatchNorma  (None, 32, 32, 128)  512        ['conv4_block17_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block17_1_relu (Activati  (None, 32, 32, 128)  0          ['conv4_block17_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block17_2_conv (Conv2D)  (None, 32, 32, 32)   36864       ['conv4_block17_1_relu[0][0]']   \n                                                                                                  \n conv4_block17_concat (Concaten  (None, 32, 32, 800)  0          ['conv4_block16_concat[0][0]',   \n ate)                                                             'conv4_block17_2_conv[0][0]']   \n                                                                                                  \n conv4_block18_0_bn (BatchNorma  (None, 32, 32, 800)  3200       ['conv4_block17_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block18_0_relu (Activati  (None, 32, 32, 800)  0          ['conv4_block18_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block18_1_conv (Conv2D)  (None, 32, 32, 128)  102400      ['conv4_block18_0_relu[0][0]']   \n                                                                                                  \n conv4_block18_1_bn (BatchNorma  (None, 32, 32, 128)  512        ['conv4_block18_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block18_1_relu (Activati  (None, 32, 32, 128)  0          ['conv4_block18_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block18_2_conv (Conv2D)  (None, 32, 32, 32)   36864       ['conv4_block18_1_relu[0][0]']   \n                                                                                                  \n conv4_block18_concat (Concaten  (None, 32, 32, 832)  0          ['conv4_block17_concat[0][0]',   \n ate)                                                             'conv4_block18_2_conv[0][0]']   \n                                                                                                  \n conv4_block19_0_bn (BatchNorma  (None, 32, 32, 832)  3328       ['conv4_block18_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block19_0_relu (Activati  (None, 32, 32, 832)  0          ['conv4_block19_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block19_1_conv (Conv2D)  (None, 32, 32, 128)  106496      ['conv4_block19_0_relu[0][0]']   \n                                                                                                  \n conv4_block19_1_bn (BatchNorma  (None, 32, 32, 128)  512        ['conv4_block19_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block19_1_relu (Activati  (None, 32, 32, 128)  0          ['conv4_block19_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block19_2_conv (Conv2D)  (None, 32, 32, 32)   36864       ['conv4_block19_1_relu[0][0]']   \n                                                                                                  \n conv4_block19_concat (Concaten  (None, 32, 32, 864)  0          ['conv4_block18_concat[0][0]',   \n ate)                                                             'conv4_block19_2_conv[0][0]']   \n                                                                                                  \n conv4_block20_0_bn (BatchNorma  (None, 32, 32, 864)  3456       ['conv4_block19_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block20_0_relu (Activati  (None, 32, 32, 864)  0          ['conv4_block20_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block20_1_conv (Conv2D)  (None, 32, 32, 128)  110592      ['conv4_block20_0_relu[0][0]']   \n                                                                                                  \n conv4_block20_1_bn (BatchNorma  (None, 32, 32, 128)  512        ['conv4_block20_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block20_1_relu (Activati  (None, 32, 32, 128)  0          ['conv4_block20_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block20_2_conv (Conv2D)  (None, 32, 32, 32)   36864       ['conv4_block20_1_relu[0][0]']   \n                                                                                                  \n conv4_block20_concat (Concaten  (None, 32, 32, 896)  0          ['conv4_block19_concat[0][0]',   \n ate)                                                             'conv4_block20_2_conv[0][0]']   \n                                                                                                  \n conv4_block21_0_bn (BatchNorma  (None, 32, 32, 896)  3584       ['conv4_block20_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block21_0_relu (Activati  (None, 32, 32, 896)  0          ['conv4_block21_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block21_1_conv (Conv2D)  (None, 32, 32, 128)  114688      ['conv4_block21_0_relu[0][0]']   \n                                                                                                  \n conv4_block21_1_bn (BatchNorma  (None, 32, 32, 128)  512        ['conv4_block21_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block21_1_relu (Activati  (None, 32, 32, 128)  0          ['conv4_block21_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block21_2_conv (Conv2D)  (None, 32, 32, 32)   36864       ['conv4_block21_1_relu[0][0]']   \n                                                                                                  \n conv4_block21_concat (Concaten  (None, 32, 32, 928)  0          ['conv4_block20_concat[0][0]',   \n ate)                                                             'conv4_block21_2_conv[0][0]']   \n                                                                                                  \n conv4_block22_0_bn (BatchNorma  (None, 32, 32, 928)  3712       ['conv4_block21_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block22_0_relu (Activati  (None, 32, 32, 928)  0          ['conv4_block22_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block22_1_conv (Conv2D)  (None, 32, 32, 128)  118784      ['conv4_block22_0_relu[0][0]']   \n                                                                                                  \n conv4_block22_1_bn (BatchNorma  (None, 32, 32, 128)  512        ['conv4_block22_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block22_1_relu (Activati  (None, 32, 32, 128)  0          ['conv4_block22_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block22_2_conv (Conv2D)  (None, 32, 32, 32)   36864       ['conv4_block22_1_relu[0][0]']   \n                                                                                                  \n conv4_block22_concat (Concaten  (None, 32, 32, 960)  0          ['conv4_block21_concat[0][0]',   \n ate)                                                             'conv4_block22_2_conv[0][0]']   \n                                                                                                  \n conv4_block23_0_bn (BatchNorma  (None, 32, 32, 960)  3840       ['conv4_block22_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block23_0_relu (Activati  (None, 32, 32, 960)  0          ['conv4_block23_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block23_1_conv (Conv2D)  (None, 32, 32, 128)  122880      ['conv4_block23_0_relu[0][0]']   \n                                                                                                  \n conv4_block23_1_bn (BatchNorma  (None, 32, 32, 128)  512        ['conv4_block23_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block23_1_relu (Activati  (None, 32, 32, 128)  0          ['conv4_block23_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block23_2_conv (Conv2D)  (None, 32, 32, 32)   36864       ['conv4_block23_1_relu[0][0]']   \n                                                                                                  \n conv4_block23_concat (Concaten  (None, 32, 32, 992)  0          ['conv4_block22_concat[0][0]',   \n ate)                                                             'conv4_block23_2_conv[0][0]']   \n                                                                                                  \n conv4_block24_0_bn (BatchNorma  (None, 32, 32, 992)  3968       ['conv4_block23_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block24_0_relu (Activati  (None, 32, 32, 992)  0          ['conv4_block24_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block24_1_conv (Conv2D)  (None, 32, 32, 128)  126976      ['conv4_block24_0_relu[0][0]']   \n                                                                                                  \n conv4_block24_1_bn (BatchNorma  (None, 32, 32, 128)  512        ['conv4_block24_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv4_block24_1_relu (Activati  (None, 32, 32, 128)  0          ['conv4_block24_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv4_block24_2_conv (Conv2D)  (None, 32, 32, 32)   36864       ['conv4_block24_1_relu[0][0]']   \n                                                                                                  \n conv4_block24_concat (Concaten  (None, 32, 32, 1024  0          ['conv4_block23_concat[0][0]',   \n ate)                           )                                 'conv4_block24_2_conv[0][0]']   \n                                                                                                  \n pool4_bn (BatchNormalization)  (None, 32, 32, 1024  4096        ['conv4_block24_concat[0][0]']   \n                                )                                                                 \n                                                                                                  \n pool4_relu (Activation)        (None, 32, 32, 1024  0           ['pool4_bn[0][0]']               \n                                )                                                                 \n                                                                                                  \n pool4_conv (Conv2D)            (None, 32, 32, 512)  524288      ['pool4_relu[0][0]']             \n                                                                                                  \n pool4_pool (AveragePooling2D)  (None, 16, 16, 512)  0           ['pool4_conv[0][0]']             \n                                                                                                  \n conv5_block1_0_bn (BatchNormal  (None, 16, 16, 512)  2048       ['pool4_pool[0][0]']             \n ization)                                                                                         \n                                                                                                  \n conv5_block1_0_relu (Activatio  (None, 16, 16, 512)  0          ['conv5_block1_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block1_1_conv (Conv2D)   (None, 16, 16, 128)  65536       ['conv5_block1_0_relu[0][0]']    \n                                                                                                  \n conv5_block1_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv5_block1_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block1_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv5_block1_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block1_2_conv (Conv2D)   (None, 16, 16, 32)   36864       ['conv5_block1_1_relu[0][0]']    \n                                                                                                  \n conv5_block1_concat (Concatena  (None, 16, 16, 544)  0          ['pool4_pool[0][0]',             \n te)                                                              'conv5_block1_2_conv[0][0]']    \n                                                                                                  \n conv5_block2_0_bn (BatchNormal  (None, 16, 16, 544)  2176       ['conv5_block1_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block2_0_relu (Activatio  (None, 16, 16, 544)  0          ['conv5_block2_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block2_1_conv (Conv2D)   (None, 16, 16, 128)  69632       ['conv5_block2_0_relu[0][0]']    \n                                                                                                  \n conv5_block2_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv5_block2_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block2_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv5_block2_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block2_2_conv (Conv2D)   (None, 16, 16, 32)   36864       ['conv5_block2_1_relu[0][0]']    \n                                                                                                  \n conv5_block2_concat (Concatena  (None, 16, 16, 576)  0          ['conv5_block1_concat[0][0]',    \n te)                                                              'conv5_block2_2_conv[0][0]']    \n                                                                                                  \n conv5_block3_0_bn (BatchNormal  (None, 16, 16, 576)  2304       ['conv5_block2_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block3_0_relu (Activatio  (None, 16, 16, 576)  0          ['conv5_block3_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block3_1_conv (Conv2D)   (None, 16, 16, 128)  73728       ['conv5_block3_0_relu[0][0]']    \n                                                                                                  \n conv5_block3_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv5_block3_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block3_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv5_block3_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block3_2_conv (Conv2D)   (None, 16, 16, 32)   36864       ['conv5_block3_1_relu[0][0]']    \n                                                                                                  \n conv5_block3_concat (Concatena  (None, 16, 16, 608)  0          ['conv5_block2_concat[0][0]',    \n te)                                                              'conv5_block3_2_conv[0][0]']    \n                                                                                                  \n conv5_block4_0_bn (BatchNormal  (None, 16, 16, 608)  2432       ['conv5_block3_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block4_0_relu (Activatio  (None, 16, 16, 608)  0          ['conv5_block4_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block4_1_conv (Conv2D)   (None, 16, 16, 128)  77824       ['conv5_block4_0_relu[0][0]']    \n                                                                                                  \n conv5_block4_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv5_block4_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block4_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv5_block4_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block4_2_conv (Conv2D)   (None, 16, 16, 32)   36864       ['conv5_block4_1_relu[0][0]']    \n                                                                                                  \n conv5_block4_concat (Concatena  (None, 16, 16, 640)  0          ['conv5_block3_concat[0][0]',    \n te)                                                              'conv5_block4_2_conv[0][0]']    \n                                                                                                  \n conv5_block5_0_bn (BatchNormal  (None, 16, 16, 640)  2560       ['conv5_block4_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block5_0_relu (Activatio  (None, 16, 16, 640)  0          ['conv5_block5_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block5_1_conv (Conv2D)   (None, 16, 16, 128)  81920       ['conv5_block5_0_relu[0][0]']    \n                                                                                                  \n conv5_block5_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv5_block5_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block5_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv5_block5_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block5_2_conv (Conv2D)   (None, 16, 16, 32)   36864       ['conv5_block5_1_relu[0][0]']    \n                                                                                                  \n conv5_block5_concat (Concatena  (None, 16, 16, 672)  0          ['conv5_block4_concat[0][0]',    \n te)                                                              'conv5_block5_2_conv[0][0]']    \n                                                                                                  \n conv5_block6_0_bn (BatchNormal  (None, 16, 16, 672)  2688       ['conv5_block5_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block6_0_relu (Activatio  (None, 16, 16, 672)  0          ['conv5_block6_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block6_1_conv (Conv2D)   (None, 16, 16, 128)  86016       ['conv5_block6_0_relu[0][0]']    \n                                                                                                  \n conv5_block6_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv5_block6_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block6_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv5_block6_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block6_2_conv (Conv2D)   (None, 16, 16, 32)   36864       ['conv5_block6_1_relu[0][0]']    \n                                                                                                  \n conv5_block6_concat (Concatena  (None, 16, 16, 704)  0          ['conv5_block5_concat[0][0]',    \n te)                                                              'conv5_block6_2_conv[0][0]']    \n                                                                                                  \n conv5_block7_0_bn (BatchNormal  (None, 16, 16, 704)  2816       ['conv5_block6_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block7_0_relu (Activatio  (None, 16, 16, 704)  0          ['conv5_block7_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block7_1_conv (Conv2D)   (None, 16, 16, 128)  90112       ['conv5_block7_0_relu[0][0]']    \n                                                                                                  \n conv5_block7_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv5_block7_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block7_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv5_block7_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block7_2_conv (Conv2D)   (None, 16, 16, 32)   36864       ['conv5_block7_1_relu[0][0]']    \n                                                                                                  \n conv5_block7_concat (Concatena  (None, 16, 16, 736)  0          ['conv5_block6_concat[0][0]',    \n te)                                                              'conv5_block7_2_conv[0][0]']    \n                                                                                                  \n conv5_block8_0_bn (BatchNormal  (None, 16, 16, 736)  2944       ['conv5_block7_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block8_0_relu (Activatio  (None, 16, 16, 736)  0          ['conv5_block8_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block8_1_conv (Conv2D)   (None, 16, 16, 128)  94208       ['conv5_block8_0_relu[0][0]']    \n                                                                                                  \n conv5_block8_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv5_block8_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block8_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv5_block8_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block8_2_conv (Conv2D)   (None, 16, 16, 32)   36864       ['conv5_block8_1_relu[0][0]']    \n                                                                                                  \n conv5_block8_concat (Concatena  (None, 16, 16, 768)  0          ['conv5_block7_concat[0][0]',    \n te)                                                              'conv5_block8_2_conv[0][0]']    \n                                                                                                  \n conv5_block9_0_bn (BatchNormal  (None, 16, 16, 768)  3072       ['conv5_block8_concat[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block9_0_relu (Activatio  (None, 16, 16, 768)  0          ['conv5_block9_0_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block9_1_conv (Conv2D)   (None, 16, 16, 128)  98304       ['conv5_block9_0_relu[0][0]']    \n                                                                                                  \n conv5_block9_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv5_block9_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block9_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv5_block9_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block9_2_conv (Conv2D)   (None, 16, 16, 32)   36864       ['conv5_block9_1_relu[0][0]']    \n                                                                                                  \n conv5_block9_concat (Concatena  (None, 16, 16, 800)  0          ['conv5_block8_concat[0][0]',    \n te)                                                              'conv5_block9_2_conv[0][0]']    \n                                                                                                  \n conv5_block10_0_bn (BatchNorma  (None, 16, 16, 800)  3200       ['conv5_block9_concat[0][0]']    \n lization)                                                                                        \n                                                                                                  \n conv5_block10_0_relu (Activati  (None, 16, 16, 800)  0          ['conv5_block10_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block10_1_conv (Conv2D)  (None, 16, 16, 128)  102400      ['conv5_block10_0_relu[0][0]']   \n                                                                                                  \n conv5_block10_1_bn (BatchNorma  (None, 16, 16, 128)  512        ['conv5_block10_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv5_block10_1_relu (Activati  (None, 16, 16, 128)  0          ['conv5_block10_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block10_2_conv (Conv2D)  (None, 16, 16, 32)   36864       ['conv5_block10_1_relu[0][0]']   \n                                                                                                  \n conv5_block10_concat (Concaten  (None, 16, 16, 832)  0          ['conv5_block9_concat[0][0]',    \n ate)                                                             'conv5_block10_2_conv[0][0]']   \n                                                                                                  \n conv5_block11_0_bn (BatchNorma  (None, 16, 16, 832)  3328       ['conv5_block10_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv5_block11_0_relu (Activati  (None, 16, 16, 832)  0          ['conv5_block11_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block11_1_conv (Conv2D)  (None, 16, 16, 128)  106496      ['conv5_block11_0_relu[0][0]']   \n                                                                                                  \n conv5_block11_1_bn (BatchNorma  (None, 16, 16, 128)  512        ['conv5_block11_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv5_block11_1_relu (Activati  (None, 16, 16, 128)  0          ['conv5_block11_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block11_2_conv (Conv2D)  (None, 16, 16, 32)   36864       ['conv5_block11_1_relu[0][0]']   \n                                                                                                  \n conv5_block11_concat (Concaten  (None, 16, 16, 864)  0          ['conv5_block10_concat[0][0]',   \n ate)                                                             'conv5_block11_2_conv[0][0]']   \n                                                                                                  \n conv5_block12_0_bn (BatchNorma  (None, 16, 16, 864)  3456       ['conv5_block11_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv5_block12_0_relu (Activati  (None, 16, 16, 864)  0          ['conv5_block12_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block12_1_conv (Conv2D)  (None, 16, 16, 128)  110592      ['conv5_block12_0_relu[0][0]']   \n                                                                                                  \n conv5_block12_1_bn (BatchNorma  (None, 16, 16, 128)  512        ['conv5_block12_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv5_block12_1_relu (Activati  (None, 16, 16, 128)  0          ['conv5_block12_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block12_2_conv (Conv2D)  (None, 16, 16, 32)   36864       ['conv5_block12_1_relu[0][0]']   \n                                                                                                  \n conv5_block12_concat (Concaten  (None, 16, 16, 896)  0          ['conv5_block11_concat[0][0]',   \n ate)                                                             'conv5_block12_2_conv[0][0]']   \n                                                                                                  \n conv5_block13_0_bn (BatchNorma  (None, 16, 16, 896)  3584       ['conv5_block12_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv5_block13_0_relu (Activati  (None, 16, 16, 896)  0          ['conv5_block13_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block13_1_conv (Conv2D)  (None, 16, 16, 128)  114688      ['conv5_block13_0_relu[0][0]']   \n                                                                                                  \n conv5_block13_1_bn (BatchNorma  (None, 16, 16, 128)  512        ['conv5_block13_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv5_block13_1_relu (Activati  (None, 16, 16, 128)  0          ['conv5_block13_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block13_2_conv (Conv2D)  (None, 16, 16, 32)   36864       ['conv5_block13_1_relu[0][0]']   \n                                                                                                  \n conv5_block13_concat (Concaten  (None, 16, 16, 928)  0          ['conv5_block12_concat[0][0]',   \n ate)                                                             'conv5_block13_2_conv[0][0]']   \n                                                                                                  \n conv5_block14_0_bn (BatchNorma  (None, 16, 16, 928)  3712       ['conv5_block13_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv5_block14_0_relu (Activati  (None, 16, 16, 928)  0          ['conv5_block14_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block14_1_conv (Conv2D)  (None, 16, 16, 128)  118784      ['conv5_block14_0_relu[0][0]']   \n                                                                                                  \n conv5_block14_1_bn (BatchNorma  (None, 16, 16, 128)  512        ['conv5_block14_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv5_block14_1_relu (Activati  (None, 16, 16, 128)  0          ['conv5_block14_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block14_2_conv (Conv2D)  (None, 16, 16, 32)   36864       ['conv5_block14_1_relu[0][0]']   \n                                                                                                  \n conv5_block14_concat (Concaten  (None, 16, 16, 960)  0          ['conv5_block13_concat[0][0]',   \n ate)                                                             'conv5_block14_2_conv[0][0]']   \n                                                                                                  \n conv5_block15_0_bn (BatchNorma  (None, 16, 16, 960)  3840       ['conv5_block14_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv5_block15_0_relu (Activati  (None, 16, 16, 960)  0          ['conv5_block15_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block15_1_conv (Conv2D)  (None, 16, 16, 128)  122880      ['conv5_block15_0_relu[0][0]']   \n                                                                                                  \n conv5_block15_1_bn (BatchNorma  (None, 16, 16, 128)  512        ['conv5_block15_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv5_block15_1_relu (Activati  (None, 16, 16, 128)  0          ['conv5_block15_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block15_2_conv (Conv2D)  (None, 16, 16, 32)   36864       ['conv5_block15_1_relu[0][0]']   \n                                                                                                  \n conv5_block15_concat (Concaten  (None, 16, 16, 992)  0          ['conv5_block14_concat[0][0]',   \n ate)                                                             'conv5_block15_2_conv[0][0]']   \n                                                                                                  \n conv5_block16_0_bn (BatchNorma  (None, 16, 16, 992)  3968       ['conv5_block15_concat[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv5_block16_0_relu (Activati  (None, 16, 16, 992)  0          ['conv5_block16_0_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block16_1_conv (Conv2D)  (None, 16, 16, 128)  126976      ['conv5_block16_0_relu[0][0]']   \n                                                                                                  \n conv5_block16_1_bn (BatchNorma  (None, 16, 16, 128)  512        ['conv5_block16_1_conv[0][0]']   \n lization)                                                                                        \n                                                                                                  \n conv5_block16_1_relu (Activati  (None, 16, 16, 128)  0          ['conv5_block16_1_bn[0][0]']     \n on)                                                                                              \n                                                                                                  \n conv5_block16_2_conv (Conv2D)  (None, 16, 16, 32)   36864       ['conv5_block16_1_relu[0][0]']   \n                                                                                                  \n conv5_block16_concat (Concaten  (None, 16, 16, 1024  0          ['conv5_block15_concat[0][0]',   \n ate)                           )                                 'conv5_block16_2_conv[0][0]']   \n                                                                                                  \n bn (BatchNormalization)        (None, 16, 16, 1024  4096        ['conv5_block16_concat[0][0]']   \n                                )                                                                 \n                                                                                                  \n relu (Activation)              (None, 16, 16, 1024  0           ['bn[0][0]']                     \n                                )                                                                 \n                                                                                                  \n reshape_14 (Reshape)           (None, 256, 1024)    0           ['relu[0][0]']                   \n                                                                                                  \n tf.compat.v1.transpose_5 (TFOp  (None, 1024, 256)   0           ['reshape_14[0][0]']             \n Lambda)                                                                                          \n                                                                                                  \n tf.compat.v1.transpose_6 (TFOp  (None, 1024, 256)   0           ['reshape_14[0][0]']             \n Lambda)                                                                                          \n                                                                                                  \n tf.linalg.matmul_7 (TFOpLambda  (None, 1024, 1024)  0           ['tf.compat.v1.transpose_5[0][0]'\n )                                                               , 'reshape_14[0][0]']            \n                                                                                                  \n tf.linalg.matmul_9 (TFOpLambda  (None, 1024, 1024)  0           ['tf.compat.v1.transpose_6[0][0]'\n )                                                               , 'reshape_14[0][0]']            \n                                                                                                  \n activation_6 (Activation)      (None, 1024, 1024)   0           ['tf.linalg.matmul_7[0][0]']     \n                                                                                                  \n activation_7 (Activation)      (None, 1024, 1024)   0           ['tf.linalg.matmul_9[0][0]']     \n                                                                                                  \n tf.linalg.matmul_8 (TFOpLambda  (None, 256, 1024)   0           ['reshape_14[0][0]',             \n )                                                                'activation_6[0][0]']           \n                                                                                                  \n tf.linalg.matmul_10 (TFOpLambd  (None, 256, 1024)   0           ['reshape_14[0][0]',             \n a)                                                               'activation_7[0][0]']           \n                                                                                                  \n reshape_17 (Reshape)           (None, 16, 16, 1024  0           ['tf.linalg.matmul_8[0][0]']     \n                                )                                                                 \n                                                                                                  \n reshape_18 (Reshape)           (None, 16, 16, 1024  0           ['tf.linalg.matmul_10[0][0]']    \n                                )                                                                 \n                                                                                                  \n conv2d_9 (Conv2D)              (None, 16, 16, 512)  66048       ['conv5_block16_1_relu[0][0]']   \n                                                                                                  \n conv2d_10 (Conv2D)             (None, 16, 16, 512)  492032      ['conv5_block15_0_relu[0][0]']   \n                                                                                                  \n concatenate_1 (Concatenate)    (None, 16, 16, 3072  0           ['reshape_17[0][0]',             \n                                )                                 'reshape_18[0][0]',             \n                                                                  'relu[0][0]']                   \n                                                                                                  \n conv2d_8 (Conv2D)              (None, 16, 16, 512)  524800      ['relu[0][0]']                   \n                                                                                                  \n reshape_21 (Reshape)           (None, 256, 512)     0           ['conv2d_9[0][0]']               \n                                                                                                  \n reshape_22 (Reshape)           (None, 256, 512)     0           ['conv2d_10[0][0]']              \n                                                                                                  \n conv2d_7 (Conv2D)              (None, 16, 16, 1024  3146752     ['concatenate_1[0][0]']          \n                                )                                                                 \n                                                                                                  \n reshape_20 (Reshape)           (None, 256, 512)     0           ['conv2d_8[0][0]']               \n                                                                                                  \n tf.compat.v1.transpose_7 (TFOp  (None, 512, 256)    0           ['reshape_21[0][0]']             \n Lambda)                                                                                          \n                                                                                                  \n tf.compat.v1.transpose_8 (TFOp  (None, 512, 256)    0           ['reshape_22[0][0]']             \n Lambda)                                                                                          \n                                                                                                  \n activation_8 (Activation)      (None, 16, 16, 1024  0           ['conv2d_7[0][0]']               \n                                )                                                                 \n                                                                                                  \n tf.linalg.matmul_11 (TFOpLambd  (None, 256, 256)    0           ['reshape_20[0][0]',             \n a)                                                               'tf.compat.v1.transpose_7[0][0]'\n                                                                 ]                                \n                                                                                                  \n tf.linalg.matmul_13 (TFOpLambd  (None, 256, 256)    0           ['reshape_20[0][0]',             \n a)                                                               'tf.compat.v1.transpose_8[0][0]'\n                                                                 ]                                \n                                                                                                  \n activation_9 (Activation)      (None, 256, 256)     0           ['tf.linalg.matmul_11[0][0]']    \n                                                                                                  \n reshape_19 (Reshape)           (None, 256, 1024)    0           ['activation_8[0][0]']           \n                                                                                                  \n activation_10 (Activation)     (None, 256, 256)     0           ['tf.linalg.matmul_13[0][0]']    \n                                                                                                  \n tf.linalg.matmul_12 (TFOpLambd  (None, 256, 1024)   0           ['activation_9[0][0]',           \n a)                                                               'reshape_19[0][0]']             \n                                                                                                  \n tf.linalg.matmul_14 (TFOpLambd  (None, 256, 1024)   0           ['activation_10[0][0]',          \n a)                                                               'reshape_19[0][0]']             \n                                                                                                  \n concatenate_2 (Concatenate)    (None, 256, 2560)    0           ['tf.linalg.matmul_12[0][0]',    \n                                                                  'tf.linalg.matmul_14[0][0]',    \n                                                                  'reshape_20[0][0]']             \n                                                                                                  \n reshape_23 (Reshape)           (None, 16, 16, 2560  0           ['concatenate_2[0][0]']          \n                                )                                                                 \n                                                                                                  \n conv2d_11 (Conv2D)             (None, 16, 16, 1024  2622464     ['reshape_23[0][0]']             \n                                )                                                                 \n                                                                                                  \n activation_11 (Activation)     (None, 16, 16, 1024  0           ['conv2d_11[0][0]']              \n                                )                                                                 \n                                                                                                  \n add (Add)                      (None, 16, 16, 1024  0           ['activation_11[0][0]',          \n                                )                                 'relu[0][0]']                   \n                                                                                                  \n concatenate_3 (Concatenate)    (None, 16, 16, 2048  0           ['activation_8[0][0]',           \n                                )                                 'add[0][0]']                    \n                                                                                                  \n global_average_pooling2d (Glob  (None, 2048)        0           ['concatenate_3[0][0]']          \n alAveragePooling2D)                                                                              \n                                                                                                  \n dense (Dense)                  (None, 5)            10245       ['global_average_pooling2d[0][0]'\n                                                                 ]                                \n                                                                                                  \n==================================================================================================\nTotal params: 13,899,845\nTrainable params: 13,816,197\nNon-trainable params: 83,648\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"history=train_model(parallel_model,image_size,batch_size,'resnet_',lr1,lr2,1,70)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"075496dd","outputId":"b085b717-c3d4-4469-a0cb-47b20750a624","execution":{"iopub.status.busy":"2023-06-17T19:32:26.078873Z","iopub.execute_input":"2023-06-17T19:32:26.079228Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Found 6260 images belonging to 5 classes.\nFound 2503 images belonging to 5 classes.\n392/391 [==============================] - ETA: 0s - loss: 0.9531 - accuracy: 0.6375","output_type":"stream"}]},{"cell_type":"code","source":"plotmodel(history,'resnet_')","metadata":{"id":"smyEy7KklWjd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob\nfrom tensorflow.keras.models import load_model\nfrom sklearn.metrics import confusion_matrix, f1_score, roc_auc_score\n\nloss_function = weighted_cross_entropy()\nkeras.utils.register_keras_serializable('loss_function')(loss_function)\n\nwith keras.utils.custom_object_scope({'loss_function': loss_function}):\n    model_path = max(glob.glob('/kaggle/working/new/*.h5'), key=os.path.getmtime)\n    model = load_model(model_path)\n\ntest_dir = '/kaggle/working/ddr/test/' \nbatch_size = 16\nimage_size = 512\ntest_data = ImageDataGenerator(rescale=1./255).flow_from_directory(\n    test_dir,\n    target_size=(image_size, image_size),\n    shuffle=False,\n    batch_size=batch_size\n)\n\nloss, accuracy = model.evaluate(test_data)\n\nprint(f'Test Loss: {loss}, Test Accuracy: {accuracy}')\n","metadata":{"id":"j8G2Jd4GdB0h","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\ny_true = test_data.classes\ny_pred = model.predict(test_data)\ny_pred_classes = np.argmax(y_pred, axis=1)\nconfusion_mtx = confusion_matrix(y_true, y_pred_classes)\nprint(confusion_mtx)\n\nplt.figure(figsize=(8,6))\nsns.heatmap(confusion_mtx,annot=True,fmt='d',cmap='Blues')\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\nplt.show()","metadata":{},"execution_count":27,"outputs":[{"name":"stdout","output_type":"stream","text":"[[1802    9   68    0    1]\n\n [  73   17   99    0    0]\n\n [ 320   50  962    5    7]\n\n [   1    0   44   22    4]\n\n [  18    1  107    9  140]]\n"},{"output_type":"display_data","data":{"image/png":"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","text/plain":["<Figure size 800x600 with 2 Axes>"]},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix,f1_score,roc_auc_score\n\nf=f1_score(y_true,y_pred_classes,average='weighted')\nroc=roc_auc_score(y_true,y_pred,average='weighted',multi_class='ovo')\nprint(f)\nprint(roc)","metadata":{},"execution_count":28,"outputs":[{"name":"stdout","output_type":"stream","text":"0.76460048600986\n\n0.8800220651711166\n"}]},{"cell_type":"code","source":"def weight_kappa(result,test_num):\n    weight=np.zeros((5,5),dtype='float')\n    for i in range(5):\n        for j in range(5):\n            weight[i,j]=(i-j)*(i-j)/16\n    fenzi=0\n    for i in range(5):\n        for j in range(5):\n            fenzi=fenzi+result[i,j]*weight[i,j]\n    fenmu=0\n    for i in range(5):\n        for j in range(5):\n            fenmu=fenmu+weight[i,j]*result[:,j].sum()*result[i,:].sum()\n\n    weght_kappa=1-(fenzi/(fenmu/test_num))\n    return  weght_kappa\n\n\ntest_num=0\nresult=np.zeros((5,5),dtype=int)\nrecall=np.zeros((1,5),dtype=float)\nfor i in range(5):\n        datadirs=test_dir+str(i)+'/'\n        filenames=os.listdir(datadirs)\n        num=len(filenames)\n        test_num=test_num+num\n        valid = ImageDataGenerator(rescale=1./255)\n        valid_data=valid.flow_from_directory(directory=test_dir,target_size=(image_size,image_size),\n                                             batch_size=batch_size,class_mode=None,classes=str(i))\n        predict=model.predict_generator(valid_data,steps=num/batch_size,verbose=1,workers=1)\n        predict=np.argmax(predict,axis=-1)\n        for j in range(5):\n            result[i,j]=np.sum(predict==j)\n\n# right=result[0,0]+result[1,1]+result[2,2]+result[3,3]+result[4,4]\n# print('Acc:',right/test_num)\n\nw_kappa=weight_kappa(result,test_num)\nprint('w_kappa:',w_kappa)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.models import Model\n\ndef grad_cam(model, image_path, layer_name, class_index, image_size):\n    img = image.load_img(image_path, target_size=(image_size, image_size))\n    img_orig = img.copy()\n    img = image.img_to_array(img)\n    img = np.expand_dims(img, axis=0)\n    img = preprocess_input(img)\n\n    grad_model = Model(inputs=model.input, outputs=(model.get_layer(layer_name).output, model.output))\n    with tf.GradientTape() as tape:\n        conv_outputs, predictions = grad_model(img)\n        loss = predictions[:, class_index]\n\n    output = conv_outputs[0]\n    grads = tape.gradient(loss, conv_outputs)[0]\n\n    weights = tf.reduce_mean(grads, axis=(0, 1))\n    cam = np.dot(output, weights)\n\n    cam = cv2.resize(cam, (image_size, image_size))\n    cam = np.maximum(cam, 0)\n    cam = cam / np.max(cam)\n\n    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n\n    img_orig = np.array(img_orig) \n    overlaid_img = cv2.addWeighted(img_orig, 0.7, heatmap, 0.3, 0)\n\n    return overlaid_img\n\n\nimage_path = '/home/dipankar/dipankar/tushir/ddr/train/3/007-2766-100.jpg'  \nlayer_name = 'reshape_2'  \nclass_index =4\n\nimage_size = 512 \n\noverlaid_img  = grad_cam(parallel_model, image_path, layer_name, class_index, image_size)\noriginal_img = image.load_img(image_path, target_size=(image_size, image_size))\nfig, axs = plt.subplots(1, 2, figsize=(10, 5))\naxs[0].imshow(original_img)\naxs[0].axis('off')\naxs[0].set_title('Original Image')\naxs[1].imshow(overlaid_img)\naxs[1].axis('off')\naxs[1].set_title('Overlaid Image with Heatmap')\nplt.show()\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":446},"id":"RD11r5fCGlZf","outputId":"1d446e7d-4981-47b2-954c-efc4de3fc528"},"execution_count":null,"outputs":[]}]}